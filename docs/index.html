<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>pyarmnn API documentation</title>
<meta name="description" content="About PyArmNN â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>pyarmnn</code></h1>
</header>
<section id="section-intro">
<h1 id="about-pyarmnn">About PyArmNN</h1>
<p>PyArmNN is a python extension for <a href="https://developer.arm.com/ip-products/processors/machine-learning/arm-nn">Arm NN SDK</a>.
PyArmNN provides interface similar to Arm NN C++ Api.</p>
<p>This repository provides resources to create a standalone build and prebuilt binaries for Arm NN 19.08, 19.11 and 20.02. Since 20.05 PyArmNN is integrated into Arm NN itself. It is also targetted for the <a href="https://www.nxp.com/products/processors-and-microcontrollers/arm-processors/i-mx-applications-processors/i-mx-8-processors:IMX8-SERIES">NXP i.MX8 series</a>, which runs Yocto Linux on aarch64, other platforms are not tested.</p>
<p>Before you proceed with building or installing, you will need to checkout and build a corresponding <a href="https://source.codeaurora.org/external/imx/armnn-imx/">Arm NN version</a>. You may also find the libraries and header files in <code>/usr/lib</code> and <code>/usr/include</code> on your Yocto image.</p>
<p>PyArmNN is built around public Arm NN headers. PyArmNN does not implement any computation kernels itself, all operations are
delegated to the Arm NN C++ library.</p>
<p>The <a href="http://www.swig.org/">SWIG</a> project is used to generate the Arm NN python shadow classes and C wrapper.</p>
<h1 id="setup-development-environment">Setup development environment</h1>
<p>Before, proceeding to the next steps, make sure that:</p>
<ol>
<li>You have Python 3.6+ installed system-side. The package is not compatible with older Python versions.</li>
<li>You have python3.6-dev installed system-side. This contains header files needed to build PyArmNN extension module.</li>
<li>In case you build Python from sources manually, make sure that the following libraries are installed and available in you system:
<code>python3.6-dev build-essential checkinstall libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev</code></li>
<li>Install SWIG 4.x. Only 3.x version is typically available in Linux package managers, so you will have to build it and install it from sources. It can be downloaded from the <a href="http://www.swig.org/download.html">SWIG project website</a> or from <a href="https://github.com/swig/swig">SWIG GitHub</a>. To install it follow the guide on <a href="https://github.com/swig/swig/wiki/Getting-Started">SWIG GitHub</a>.</li>
</ol>
<h2 id="setup-virtual-environment">Setup virtual environment</h2>
<p>Now you can proceed with setting up workspace. It is recommended to create a python virtual environment, so you do not pollute your working folder:</p>
<pre><code class="bash">python3 -m venv env
source env/bin/activate
</code></pre>
<p>You may run into missing python modules such as <em>wheel</em>. Make sure to install those using pip:</p>
<pre><code class="bash">pip install wheel
</code></pre>
<h2 id="build-python-distr">Build python distr</h2>
<p>Python supports source and binary distribution packages.</p>
<p>Source distr contains setup.py script that is executed on the users machine during package installation.
When preparing binary distr (wheel), setup.py is executed on the build machine and the resulting package contains only the result
of the build (generated files and resources, test results etc).</p>
<p>In our case, PyArmNN depends on Arm NN installation. Thus, binary distr will be linked with
the local build machine libraries and runtime.</p>
<p>There are 2 ways to build the python packages. Either directly using the python scripts or using CMake.</p>
<h3 id="cmake-build">CMake build</h3>
<p>The recommended aproach is to build PyArmNN using CMake. First run the cmake command from the build directory and then run make:</p>
<pre><code>mkdir build
cd build
cmake .. \
-DBUILD_PYTHON_SRC=&lt;0 or 1&gt; \
-DBUILD_PYTHON_WHL=&lt;0 or 1&gt; \ 
-DARMNN_LIB=&lt;path_to_armnn_libs&gt; \
-DARMNN_INCLUDE=&lt;path_to_armnn_headers&gt; \
-DSWIG_EXECUTABLE=&lt;path_to_swig_executable&gt;
make
</code></pre>
<p><code>BUILD_PYTHON_SRC</code> can be set to 0 or 1 depending if you want to build the python source package. </p>
<p><code>BUILD_PYTHON_WHL</code> can be set to 0 or 1 depending if you want to build the python wheel (binary package).</p>
<p><code>ARMNN_LIB</code> should point to the directory where Arm NN libraries can be found.</p>
<p><code>ARMNN_INCLUDE</code> should point to the directory where Arm NN headers can be found.</p>
<p><code>SWIG_EXECUTABLE</code> is optional. Run <code>swig -version</code> to see what version of swig is called. If it's 4.x, you are good to go, otherwise you should set this variable to point to the swig executable (not the directory).</p>
<p>After the build finishes, you will find the python packages in <code>&lt;build_folder&gt;/python/pyarmnn/dist</code>.</p>
<h3 id="standalone-build">Standalone build</h3>
<p>PyArmNN can also be built using the provided python scripts only. The advantage of that is that you may use prebuilt Arm NN libraries and it is generally much faster if you do not want to build all the Arm NN libraries.</p>
<p>First navigate to the <code>python/pyarmnn</code> directory.</p>
<pre><code class="bash">cd python/pyarmnn
</code></pre>
<h5 id="1-set-environment">1. Set environment:</h5>
<p><code>ARMNN_INCLUDE</code> and <code>ARMNN_LIB</code> are mandatory and should point to Arm NN headers and libraries against which you will be generating the wrappers. <code>SWIG_EXECUTABLE</code> should only be set if you have multiple versions of SWIG installed or you used a custom location for your installation. You should also run the commands from the <code>python/pyarmnn</code> directory:</p>
<pre><code class="bash">export SWIG_EXECUTABLE=&lt;path_to_swig_exec&gt;
export ARMNN_INCLUDE=&lt;path_to_armnn_include&gt;
export ARMNN_LIB=&lt;path_to_armnn_libraries&gt;
cd python/pyarmnn
</code></pre>
<h5 id="2-clean-and-build-swig-wrappers">2. Clean and build SWIG wrappers:</h5>
<pre><code class="bash">python setup.py clean --all
python swig_generate.py -v
python setup.py build_ext --inplace
</code></pre>
<p>This step will put all generated files under <code>src/pyarmnn/_generated</code> folder and can be used repeatedly to re-generate the wrappers.</p>
<h5 id="4-build-the-source-package">4. Build the source package</h5>
<pre><code class="bash">python setup.py sdist
</code></pre>
<p>As the result you will get <code>dist/pyarmnn-19.8.1.tar.gz</code> file. As you can see it is platform independent.</p>
<h5 id="5-build-the-binary-package">5. Build the binary package</h5>
<pre><code class="bash">python setup.py bdist_wheel
</code></pre>
<p>As the result you will get something like <code>dist/pyarmnn-19.8.1-cp37-cp37m-linux_aarch64.whl</code> file. As you can see it is platform dependent.</p>
<h1 id="pyarmnn-installation">PyArmNN installation</h1>
<p>PyArmNN can be distributed as a source package or a binary package (wheel).</p>
<p>Binary package is platform dependent, the name of the package will indicate the platform it was built for, e.g.:</p>
<ul>
<li>Linux x86 64bit machine: pyarmnn-19.8.1-cp37-cp37m-<em>linux_x86_64</em>.whl</li>
<li>Linux Aarch 64 bit machine: pyarmnn-19.8.1-cp37-cp37m-<em>linux_aarch64</em>.whl</li>
</ul>
<p>The source package is platform independent but installation involves compilation of Arm NN python extension. You will need to have g++ compatible with C++ 14 standard and a python development library installed on the build machine.</p>
<p>Both of them, source and binary package, require the Arm NN library to be present on the target/build machine.</p>
<p>It is strongly suggested to work within a python virtual environment. The further steps assume that the virtual environment was created and activated before running PyArmNN installation commands.</p>
<p>PyArmNN also depends on the NumPy python library. It will be automatically downloaded and installed alongside PyArmNN. If your machine does not have access to Python pip repositories you might need to install NumPy in advance by following public instructions: <a href="https://scipy.org/install.html">https://scipy.org/install.html</a></p>
<h2 id="installing-from-wheel">Installing from wheel</h2>
<p>Make sure that Arm NN binaries and Arm NN dependencies are installed and can be found in one of the system default library locations. You can check default locations by executing the following command:</p>
<pre><code class="bash">gcc --print-search-dirs
</code></pre>
<p>Install PyArmNN from binary by pointing to the wheel file:</p>
<pre><code class="bash">pip install dist/pyarmnn-19.8.1-cp37-cp37m-linux_aarch64.whl
</code></pre>
<h2 id="installing-from-source-package">Installing from source package</h2>
<p>Alternatively, you can install from source. This is the more reliable way but requires a little more effort on the users part.</p>
<p>While installing from sources, you have the freedom of choosing Arm NN libraries location. Set environment variables <em>ARMNN_LIB</em> and <em>ARMNN_INCLUDE</em> to point to Arm NN libraries and headers.
If you want to use system default locations, just set <em>ARMNN_INCLUDE</em> to point to Arm NN headers.</p>
<pre><code class="bash">export ARMNN_INCLUDE=&lt;path_to_armnn_include&gt;
export ARMNN_LIB=&lt;path_to_armnn_libraries&gt;
</code></pre>
<p>Install PyArmNN as follows:</p>
<pre><code class="bash">pip install dist/pyarmnn-19.8.1.tar.gz
</code></pre>
<p>If PyArmNN installation script fails to find Arm NN libraries it will raise an error like this</p>
<p><code>RuntimeError: ArmNN library was not found in ('/usr/lib/gcc/aarch64-linux-gnu/8/', &lt;...&gt; ,'/lib/', '/usr/lib/'). Please install ArmNN to one of the standard locations or set correct ARMNN_INCLUDE and ARMNN_LIB env variables.</code></p>
<p>You can now verify that PyArmNN library is installed and check PyArmNN version using:</p>
<pre><code class="bash">pip show pyarmnn
</code></pre>
<p>You can also verify it by running the following and getting output similar to below:</p>
<pre><code class="bash">python -c &quot;import pyarmnn as ann;print(ann.GetVersion())&quot;
20190801
</code></pre>
<h1 id="pyarmnn-api-overview">PyArmNN API overview</h1>
<h4 id="getting-started">Getting started</h4>
<p>The easiest way to begin using PyArmNN is by using the Parsers. We will demonstrate how to use them below:</p>
<p>Create a parser object and load your model file.</p>
<pre><code class="python">import pyarmnn as ann
import imageio

# ONNX, Caffe and TF parsers also exist.
parser = ann.ITfLiteParser()
network = parser.CreateNetworkFromBinaryFile('./model.tflite')
</code></pre>
<p>Get the input binding information by using the name of the input layer.</p>
<pre><code class="python">input_binding_info = parser.GetNetworkInputBindingInfo(0, 'model/input')

# Create a runtime object that will perform inference.
options = ann.CreationOptions()
runtime = ann.IRuntime(options)
</code></pre>
<p>Choose preferred backends for execution and optimize the network.</p>
<pre><code class="python"># Backend choices earlier in the list have higher preference.
preferredBackends = [ann.BackendId('CpuAcc'), ann.BackendId('CpuRef')]
opt_network, messages = ann.Optimize(network, preferredBackends, runtime.GetDeviceSpec(), ann.OptimizerOptions())

# Load the optimized network into the runtime.
net_id, _ = runtime.LoadNetwork(opt_network)
</code></pre>
<p>Make workload tensors using input and output binding information.</p>
<pre><code class="python"># Load an image and create an inputTensor for inference.
img = imageio.imread('./image.png')
input_tensors = ann.make_input_tensors([input_binding_info], [img])

# Get output binding information for an output layer by using the layer name.
output_binding_info = parser.GetNetworkOutputBindingInfo(0, 'model/output')
output_tensors = ann.make_output_tensors([outputs_binding_info])
</code></pre>
<p>Perform inference and get the results back into a numpy array.</p>
<pre><code class="python">runtime.EnqueueWorkload(0, input_tensors, output_tensors)

results = ann.workload_tensors_to_ndarray(output_tensors)
print(results)
</code></pre>
<h4 id="examples">Examples</h4>
<p>To further explore PyArmNN API there are several examples provided in the examples folder running classification on an image. To run them first install the dependencies:
```bash
cd python/pyarmnn
pip install -r examples/requirements.txt</p>
<pre><code>Afterwards simply execute the example scripts, e.g.:
 ```bash
python tflite_mobilenetv1_quantized.py
</code></pre>
<p>All resources are downloaded during execution, so if you do not have access to the internet, you may need to download these manually. <code>example_utils.py</code> contains code shared between the examples.</p>
<h2 id="tox-for-automation">Tox for automation</h2>
<p>To make things easier <em>tox</em> is available for automating individual tasks or running multiple commands at once such as generating wrappers, running unit tests using multiple python versions or generating documentation. To run it use:</p>
<pre><code class="bash">tox &lt;task_name&gt;
</code></pre>
<p>See <em>tox.ini</em> for the list of tasks. You may also modify it for your own purposes. To dive deeper into tox read through <a href="https://tox.readthedocs.io/en/latest/">https://tox.readthedocs.io/en/latest/</a></p>
<p>Tox is inteded for easier automation, so you may have to modify the script slightly to work with your environment. We do not guarantee, that it works out of the box.</p>
<h2 id="running-unit-tests">Running unit-tests</h2>
<p>Download resources required to run unit tests by executing the script from the <code>python/pyarmnn</code> directory. You will also need to install required python modules.</p>
<pre><code class="bash">cd python/pyarmnn
pip install -r test/requirements.txt
python ./scripts/download_test_resources.py
</code></pre>
<p>The script will download an archive from the Linaro server and extract it. A folder <code>test/testdata/shared</code> will be created. Execute <code>pytest</code> from the project root dir:</p>
<pre><code class="bash">python -m pytest test/ -v
</code></pre>
<p>or run tox which will do both:</p>
<pre><code class="bash">tox
</code></pre>
<h2 id="prebuilt-wheels">Prebuilt wheels</h2>
<p>Prebuilt wheel packages (even older versions) can be found in the <code>whl</code> directory.</p>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pyarmnn.CreateDescriptorForConcatenation"><code class="name flex">
<span>def <span class="ident">CreateDescriptorForConcatenation</span></span>(<span>shapes, concatenationDimension)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a descriptor for Concatenation layer.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>shapes</code></strong> :&ensp;<code>list</code> of <code><a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape">TensorShape</a></code></dt>
<dd>Input shapes.</dd>
<dt><strong><code>concatenationDimension</code></strong> :&ensp;<code>unsigned int</code></dt>
<dd>Concatenation axis.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.ConcatDescriptor" href="#pyarmnn.ConcatDescriptor">ConcatDescriptor</a></code></dt>
<dd>A descriptor object for a concatenation layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.GetMajorVersion"><code class="name flex">
<span>def <span class="ident">GetMajorVersion</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns Arm NN library major version. The year of the release.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Major version of Arm NN installed.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.GetMinorVersion"><code class="name flex">
<span>def <span class="ident">GetMinorVersion</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns Arm NN library minor version. Month of the year of the release.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Minor version of Arm NN installed.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.GetVersion"><code class="name flex">
<span>def <span class="ident">GetVersion</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns Arm NN library full version: MAJOR + MINOR + INCREMENTAL.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Full version of Arm NN installed.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.Optimize"><code class="name flex">
<span>def <span class="ident">Optimize</span></span>(<span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>Create an optimized version of the given network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>network</code></strong> :&ensp;<code><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork">INetwork</a></code></dt>
<dd>INetwork description of the network to be optimized.</dd>
<dt><strong><code>backendPreferences</code></strong> :&ensp;<code>list</code></dt>
<dd>The choice of the backend ordered by user preferences. See <code><a title="pyarmnn.BackendId" href="#pyarmnn.BackendId">BackendId</a></code>.</dd>
<dt><strong><code>deviceSpec</code></strong> :&ensp;<code><a title="pyarmnn.IDeviceSpec" href="#pyarmnn.IDeviceSpec">IDeviceSpec</a></code></dt>
<dd>DeviceSpec object as queried from the runtime. See <code><a title="pyarmnn.IRuntime.GetDeviceSpec" href="#pyarmnn.IRuntime.GetDeviceSpec">IRuntime.GetDeviceSpec()</a></code>.</dd>
<dt><strong><code>options</code></strong> :&ensp;<code><a title="pyarmnn.OptimizerOptions" href="#pyarmnn.OptimizerOptions">OptimizerOptions</a></code></dt>
<dd>Object with optimizer configuration options.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(<code><a title="pyarmnn.IOptimizedNetwork" href="#pyarmnn.IOptimizedNetwork">IOptimizedNetwork</a></code>, a tuple of failures or warnings).</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If process fails.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.dequantize"><code class="name flex">
<span>def <span class="ident">dequantize</span></span>(<span>value, scale, offset, from_dtype)</span>
</code></dt>
<dd>
<div class="desc"><p>Dequantize given value from the given datatype using Armnn.</p>
<p>This function can be used to convert an 8-bit unsigned integer value or 16/32-bit
integer value into a 32-bit floating point value. Typically used when decoding an
output value from an output tensor on a quantized model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>value</code></strong> :&ensp;<code>int</code></dt>
<dd>The value to be dequantized. Value could be numpy numeric data type.</dd>
<dt><strong><code>scale</code></strong> :&ensp;<code>float</code></dt>
<dd>A numeric constant that the value is multiplied by.</dd>
<dt><strong><code>offset</code></strong> :&ensp;<code>float</code></dt>
<dd>A 'zero-point' used to 'shift' the integer range.</dd>
<dt><strong><code>from_dtype</code></strong> :&ensp;<code>str</code></dt>
<dd>The data type 'value' represents. Supported values: 'unit8', 'int16', 'int32'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>A dequantized 32-bit floating-point value.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.get_profiling_data"><code class="name flex">
<span>def <span class="ident">get_profiling_data</span></span>(<span>profiler)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads IProfiler object passed in, extracts the relevant data
and returns it in a ProfilerData container.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>profile_log</code></strong> :&ensp;<code><a title="pyarmnn.IProfiler" href="#pyarmnn.IProfiler">IProfiler</a></code></dt>
<dd>The IProfiler object to be parsed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.ProfilerData" href="#pyarmnn.ProfilerData">ProfilerData</a></code></dt>
<dd>A container containing the relevant data extracted from the Profiler output.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.make_input_tensors"><code class="name flex">
<span>def <span class="ident">make_input_tensors</span></span>(<span>inputs_binding_info, input_data)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns <code>inputTensors</code> to be used with <code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">IRuntime.EnqueueWorkload()</a></code>.</p>
<p>This is the primary function to call when you want to produce <code>inputTensors</code> for <code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">IRuntime.EnqueueWorkload()</a></code>.
The output is a list of tuples containing ConstTensors with a corresponding input tensor id.
The output should be used directly with <code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">IRuntime.EnqueueWorkload()</a></code>.
This function works for single or multiple input data and binding information.</p>
<h2 id="examples">Examples</h2>
<p>Creating inputTensors.</p>
<pre><code class="python">&gt;&gt;&gt; import pyarmnn as ann
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt;
&gt;&gt;&gt; parser = ann.ITfLiteParser()
&gt;&gt;&gt; ...
&gt;&gt;&gt; example_image = np.array(...)
&gt;&gt;&gt; input_binding_info = parser.GetNetworkInputBindingInfo(...)
&gt;&gt;&gt;
&gt;&gt;&gt; input_tensors = ann.make_input_tensors([input_binding_info], [example_image])
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>inputs_binding_info</code></strong> :&ensp;<code>list</code> of <code>tuples</code></dt>
<dd>(int, <code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>) Binding information for input tensors obtained from <code>GetNetworkInputBindingInfo</code>.</dd>
<dt><strong><code>input_data</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>Tensor data to be used for inference.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd><code>inputTensors</code> - A list of tuples (<code>int</code> , <code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code>).</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If length of <code>inputs_binding_info</code> and <code>input_data</code> are not the same.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.make_output_tensors"><code class="name flex">
<span>def <span class="ident">make_output_tensors</span></span>(<span>outputs_binding_info)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns <code>outputTensors</code> to be used with <code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">IRuntime.EnqueueWorkload()</a></code>.</p>
<p>This is the primary function to call when you want to produce <code>outputTensors</code> for <code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">IRuntime.EnqueueWorkload()</a></code>.
The output is a list of tuples containing Tensors with a corresponding output tensor id.
The output should be used directly with <code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">IRuntime.EnqueueWorkload()</a></code>.</p>
<h2 id="examples">Examples</h2>
<p>Creating outputTensors.</p>
<pre><code class="python">&gt;&gt;&gt; import pyarmnn as ann
&gt;&gt;&gt;
&gt;&gt;&gt; parser = ann.ITfLiteParser()
&gt;&gt;&gt; ...
&gt;&gt;&gt; output_binding_info = parser.GetNetworkOutputBindingInfo(...)
&gt;&gt;&gt;
&gt;&gt;&gt; output_tensors = ann.make_output_tensors([output_binding_info])
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>outputs_binding_info</code></strong> :&ensp;<code>list</code> of <code>tuples</code></dt>
<dd>(int, <code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>) Binding information for output tensors obtained from <code>GetNetworkOutputBindingInfo</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd><code>outputTensors</code> - A list of tuples (<code>int</code>, <code><a title="pyarmnn.Tensor" href="#pyarmnn.Tensor">Tensor</a></code>).</dd>
</dl></div>
</dd>
<dt id="pyarmnn.quantize"><code class="name flex">
<span>def <span class="ident">quantize</span></span>(<span>value, scale, offset, target_dtype)</span>
</code></dt>
<dd>
<div class="desc"><p>Quantize given value to the given target datatype using Arm NN.</p>
<p>This function can be used to convert a 32-bit floating point value into 16/32-bit
integer or 8-bit unsigned integer values.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>value</code></strong> :&ensp;<code>float</code></dt>
<dd>The value to be quantized.</dd>
<dt><strong><code>scale</code></strong> :&ensp;<code>float</code></dt>
<dd>A numeric constant that the value is multiplied by.</dd>
<dt><strong><code>offset</code></strong> :&ensp;<code>int</code></dt>
<dd>A 'zero-point' used to 'shift' the integer range.</dd>
<dt><strong><code>target_dtype</code></strong> :&ensp;<code>str</code></dt>
<dd>The target data type. Supported values: 'unit8', 'int16', 'int32'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>A quantized 8-bit unsigned integer value or 16/32-bit integer value.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.workload_tensors_to_ndarray"><code class="name flex">
<span>def <span class="ident">workload_tensors_to_ndarray</span></span>(<span>workload_tensors)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list of the underlying tensor data as ndarrays from <code>inputTensors</code> or <code>outputTensors</code>.</p>
<p>We refer to <code>inputTensors</code> and <code>outputTensors</code> as workload tensors because
they are used with <code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">IRuntime.EnqueueWorkload()</a></code>.
Although this function can be used on either <code>inputTensors</code> or <code>outputTensors</code> the main use of this function
is to collect results from <code>outputTensors</code> after <code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">IRuntime.EnqueueWorkload()</a></code> has been called.</p>
<h2 id="examples">Examples</h2>
<p>Getting results after inference.</p>
<pre><code class="python">&gt;&gt;&gt; import pyarmnn as ann
&gt;&gt;&gt;
&gt;&gt;&gt; ...
&gt;&gt;&gt; runtime = ann.IRuntime(...)
&gt;&gt;&gt; ...
&gt;&gt;&gt; runtime.EnqueueWorkload(net_id, input_tensors, output_tensors)
&gt;&gt;&gt;
&gt;&gt;&gt; inference_results = tensors_to_ndarray(output_tensors)
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>workload_tensors</code></strong> :&ensp;<code>inputTensors</code> or <code>outputTensors</code></dt>
<dd><code>inputTensors</code> or <code>outputTensors</code> to get data from.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>List of <code>ndarrays</code> for the underlying tensor data from given <code>inputTensors</code> or <code>outputTensors</code>.</dd>
</dl></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pyarmnn.ActivationDescriptor"><code class="flex name class">
<span>class <span class="ident">ActivationDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A configuration for the Activation layer. See <code><a title="pyarmnn.INetwork.AddActivationLayer" href="#pyarmnn.INetwork.AddActivationLayer">INetwork.AddActivationLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_Function (ActivationFunction): The activation function to use
(Sigmoid, TanH, Linear, ReLu, BoundedReLu, SoftReLu, LeakyReLu, Abs, Sqrt, Square).
Default: ActivationFunction_Sigmoid.
m_A (float): Alpha upper bound value used by the activation functions. (BoundedReLu, Linear, TanH). Default: 0.
m_B (float): Beta lower bound value used by the activation functions. (BoundedReLu, Linear, TanH). Default: 0.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ActivationDescriptor.m_A"><code class="name">var <span class="ident">m_A</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.ActivationDescriptor.m_B"><code class="name">var <span class="ident">m_B</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.ActivationDescriptor.m_Function"><code class="name">var <span class="ident">m_Function</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.ActivationDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.BackendId"><code class="flex name class">
<span>class <span class="ident">BackendId</span></span>
<span>(</span><span>id)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates backend id instance.
Supported backend ids: 'CpuRef', 'CpuAcc', 'GpuAcc', 'NpuAcc'.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>id</code></strong> :&ensp;<code>str</code></dt>
<dd>Computation backend identification.</dd>
</dl></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.BackendId.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.BackendId.Get"><code class="name flex">
<span>def <span class="ident">Get</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns backend identification.</p>
<pre><code class="python">&gt;&gt;&gt; backendId = BackendId('CpuRef')
&gt;&gt;&gt; assert 'CpuRef' == str(backendId)
&gt;&gt;&gt; assert 'CpuRef' == backendId.Get()
</code></pre>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Backend identification.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.BackendId.IsCpuRef"><code class="name flex">
<span>def <span class="ident">IsCpuRef</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if backend is cpu reference implementation.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if backend supports cpu reference implementation, False otherwise.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.BatchNormalizationDescriptor"><code class="flex name class">
<span>class <span class="ident">BatchNormalizationDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the BatchNormalization layer.
See <code><a title="pyarmnn.INetwork.AddBatchNormalizationLayer" href="#pyarmnn.INetwork.AddBatchNormalizationLayer">INetwork.AddBatchNormalizationLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_Eps (float): Value to add to the variance. Used to avoid dividing by zero. Default: 0.0001f.
m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.BatchNormalizationDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.BatchNormalizationDescriptor.m_Eps"><code class="name">var <span class="ident">m_Eps</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.BatchNormalizationDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.BatchToSpaceNdDescriptor"><code class="flex name class">
<span>class <span class="ident">BatchToSpaceNdDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the BatchToSpaceNd layer.
See <code><a title="pyarmnn.INetwork.AddBatchToSpaceNdLayer" href="#pyarmnn.INetwork.AddBatchToSpaceNdLayer">INetwork.AddBatchToSpaceNdLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_BlockShape (list of int): Block shape values. Default: (1, 1). Underlying C++ type is unsigned int.</p>
<p>m_Crops (list of tuple): The values to crop from the input dimension. Default: [(0, 0), (0, 0)].</p>
<p>m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.BatchToSpaceNdDescriptor.m_BlockShape"><code class="name">var <span class="ident">m_BlockShape</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.BatchToSpaceNdDescriptor.m_Crops"><code class="name">var <span class="ident">m_Crops</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.BatchToSpaceNdDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.BatchToSpaceNdDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ConcatDescriptor"><code class="flex name class">
<span>class <span class="ident">ConcatDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a configuration/descriptor for a Concatenation layer. See <code><a title="pyarmnn.INetwork.AddConcatLayer" href="#pyarmnn.INetwork.AddConcatLayer">INetwork.AddConcatLayer()</a></code>.
Number of Views must be equal to the number of inputs, and their order must match e.g. first view corresponds to the first input, second view to the second input, etc.</p>
<h2 id="contains">Contains</h2>
<p>numViews (int): Number of views, the value
must be equal to the number of outputs of a layer.
numDimensions (int): Number of dimensions. Default value is 4.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ConcatDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.ConcatDescriptor.GetConcatAxis"><code class="name flex">
<span>def <span class="ident">GetConcatAxis</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the concatenation dimension.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Concatenation axis index.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ConcatDescriptor.GetNumDimensions"><code class="name flex">
<span>def <span class="ident">GetNumDimensions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the number of dimensions.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of dimensions.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ConcatDescriptor.GetNumViews"><code class="name flex">
<span>def <span class="ident">GetNumViews</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the number of views.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of views.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ConcatDescriptor.GetViewOrigin"><code class="name flex">
<span>def <span class="ident">GetViewOrigin</span></span>(<span>self, idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the view origin input by index.</p>
<p>Each view match the inputs order, e.g. first view corresponds to the first input, second view to the second input, etc.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index to get view from.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>View origin (shape) specified by the int value <code>idx</code> as a list of ints.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ConcatDescriptor.SetConcatAxis"><code class="name flex">
<span>def <span class="ident">SetConcatAxis</span></span>(<span>self, concatAxis)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the concatenation dimension.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>concatAxis</code></strong> :&ensp;<code>int</code></dt>
<dd>Concatenation axis index.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ConcatDescriptor.SetViewOriginCoord"><code class="name flex">
<span>def <span class="ident">SetViewOriginCoord</span></span>(<span>self, view, coord, value)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the coordinates of a specific origin view input.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>view</code></strong> :&ensp;<code>int</code></dt>
<dd>Origin view index.</dd>
<dt><strong><code>coord</code></strong> :&ensp;<code>int</code></dt>
<dd>Coordinate of the origin view to set.</dd>
<dt><strong><code>value</code></strong> :&ensp;<code>int</code></dt>
<dd>Value to set.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If the <code>view</code> is greater than or equal to GetNumViews().</dd>
<dt><code>RuntimeError</code></dt>
<dd>If the <code>coord</code> is greater than or equal to GetNumDimensions().</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ConstTensor"><code class="flex name class">
<span>class <span class="ident">ConstTensor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a PyArmNN ConstTensor object.</p>
<p>A ConstTensor is a Tensor with an immutable data store. Typically, a ConstTensor
is used to input data into a network when running inference.</p>
<p>This class overrides the swig generated Tensor class. The aim of
this is to have an easy to use public API for the ConstTensor objects.</p>
<p>Supported tensor data types:
DataType_QuantisedAsymm8,
DataType_QuantisedSymm16,
DataType_Signed32,
DataType_Float32,
DataType_Float16</p>
<h2 id="examples">Examples</h2>
<p>Create empty ConstTensor</p>
<pre><code class="python">&gt;&gt;&gt; import pyarmnn as ann
&gt;&gt;&gt; ann.ConstTensor()
</code></pre>
<p>Create ConstTensor given tensor info and input data</p>
<pre><code class="python">&gt;&gt;&gt; input_data = ... #  numpy array
&gt;&gt;&gt; ann.ConstTensor(ann.TensorInfo(...), input_data)
</code></pre>
<p>Create ConstTensor from another ConstTensor i.e. copy ConstTensor</p>
<pre><code class="python">&gt;&gt;&gt; ann.ConstTensor(ann.ConstTensor())
</code></pre>
<p>Create ConstTensor from tensor</p>
<pre><code class="python">&gt;&gt;&gt; ann.ConstTensor(ann.Tensor())
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tensor</code></strong> :&ensp;<code><a title="pyarmnn.Tensor" href="#pyarmnn.Tensor">Tensor</a></code>, optional</dt>
<dd>Create a ConstTensor from a Tensor.</dd>
<dt><strong><code>const_tensor</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code>, optional</dt>
<dd>Create a ConstTensor from a ConstTensor i.e. copy.</dd>
<dt><strong><code>tensor_info</code></strong> :&ensp;<code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>, optional</dt>
<dd>Tensor information.</dd>
<dt><strong><code>input_data</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>Numpy array. The numpy array will be transformed to a
buffer according to type returned by <code><a title="pyarmnn.TensorInfo.GetDataType" href="#pyarmnn.TensorInfo.GetDataType">TensorInfo.GetDataType()</a></code>.
Input data values type must correspond to data type returned by
<code><a title="pyarmnn.TensorInfo.GetDataType" href="#pyarmnn.TensorInfo.GetDataType">TensorInfo.GetDataType()</a></code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>TypeError</code></dt>
<dd>Unsupported input data type.</dd>
<dt><code>ValueError</code></dt>
<dd>Unsupported tensor data type and incorrect input data size.</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pyarmnn._generated.pyarmnn.ConstTensor</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.ConstTensor.get_memory_area"><code class="name flex">
<span>def <span class="ident">get_memory_area</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get values that are stored by the tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ndarray</code></dt>
<dd>Tensor data (as numpy array).</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor"><code class="flex name class">
<span>class <span class="ident">Convolution2dDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Convolution2d layer.
See <code><a title="pyarmnn.INetwork.AddConvolution2dLayer" href="#pyarmnn.INetwork.AddConvolution2dLayer">INetwork.AddConvolution2dLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_PadLeft (int): Underlying C++ data type is <code>uint32_t</code>. Padding left value in the width dimension. Default: 0.
m_PadRight (int): Underlying C++ data type is <code>uint32_t</code>. Padding right value in the width dimension. Default: 0.
m_PadTop (int): Underlying C++ data type is <code>uint32_t</code>. Padding top value in the height dimension. Default: 0.
m_PadBottom (int): Underlying C++ data type is <code>uint32_t</code>. Padding bottom value in the height dimension. Default: 0.
m_StrideX (int): Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the width dimension. Default: 0.
m_StrideY (int): Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the height dimension. Default: 0.
m_DilationX (int): Underlying C++ data type is <code>uint32_t</code>. Dilation along x axis. Default: 1.
m_DilationY (int): Underlying C++ data type is <code>uint32_t</code>. Dilation along y axis. Default: 1.
m_BiasEnabled (bool): Enable/disable bias. Default: false.
m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.Convolution2dDescriptor.m_BiasEnabled"><code class="name">var <span class="ident">m_BiasEnabled</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_DilationX"><code class="name">var <span class="ident">m_DilationX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_DilationY"><code class="name">var <span class="ident">m_DilationY</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_PadBottom"><code class="name">var <span class="ident">m_PadBottom</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_PadLeft"><code class="name">var <span class="ident">m_PadLeft</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_PadRight"><code class="name">var <span class="ident">m_PadRight</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_PadTop"><code class="name">var <span class="ident">m_PadTop</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_StrideX"><code class="name">var <span class="ident">m_StrideX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_StrideY"><code class="name">var <span class="ident">m_StrideY</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.CreationOptions"><code class="flex name class">
<span>class <span class="ident">CreationOptions</span></span>
</code></dt>
<dd>
<div class="desc"><p>Structure for holding creation options. For majority of cases it is fine to leave values at default.</p>
<h2 id="contains">Contains</h2>
<p>m_GpuAccTunedParameters (IGpuAccTunedParameters): If set, uses the GpuAcc tuned parameters from the given object
when executing GPU workloads. It will also be updated with new
tuned parameters if it is configured to do so.</p>
<p>m_EnableGpuProfiling (bool): Setting this flag will allow the user to obtain GPU profiling information from
the runtime.</p>
<p>m_DynamicBackendsPath (string): Setting this value will override the paths set by the DYNAMIC_BACKEND_PATHS
compiler directive. Only a single path is allowed for the override.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.CreationOptions.m_DynamicBackendsPath"><code class="name">var <span class="ident">m_DynamicBackendsPath</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.CreationOptions.m_EnableGpuProfiling"><code class="name">var <span class="ident">m_EnableGpuProfiling</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.CreationOptions.m_GpuAccTunedParameters"><code class="name">var <span class="ident">m_GpuAccTunedParameters</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.CreationOptions.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor"><code class="flex name class">
<span>class <span class="ident">DepthwiseConvolution2dDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the DepthwiseConvolution2d layer. See <code><a title="pyarmnn.INetwork.AddDepthwiseConvolution2dLayer" href="#pyarmnn.INetwork.AddDepthwiseConvolution2dLayer">INetwork.AddDepthwiseConvolution2dLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_PadLeft (int): Underlying C++ data type is <code>uint32_t</code>. Padding left value in the width dimension. Default: 0.
m_PadRight (int): Underlying C++ data type is <code>uint32_t</code>. Padding right value in the width dimension. Default: 0.
m_PadTop (int): Underlying C++ data type is <code>uint32_t</code>. Padding top value in the height dimension. Default: 0.
m_PadBottom (int): Underlying C++ data type is <code>uint32_t</code>. Padding bottom value in the height dimension. Default: 0.
m_StrideX (int): Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the width dimension. Default: 0.
m_StrideY (int): Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the height dimension. Default: 0.
m_DilationX (int): Underlying C++ data type is <code>uint32_t</code>. Dilation along x axis. Default: 1.
m_DilationY (int): Underlying C++ data type is <code>uint32_t</code>. Dilation along y axis. Default: 1.
m_BiasEnabled (bool): Enable/disable bias. Default: false.
m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_BiasEnabled"><code class="name">var <span class="ident">m_BiasEnabled</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationX"><code class="name">var <span class="ident">m_DilationX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationY"><code class="name">var <span class="ident">m_DilationY</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadBottom"><code class="name">var <span class="ident">m_PadBottom</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadLeft"><code class="name">var <span class="ident">m_PadLeft</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadRight"><code class="name">var <span class="ident">m_PadRight</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadTop"><code class="name">var <span class="ident">m_PadTop</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideX"><code class="name">var <span class="ident">m_StrideX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideY"><code class="name">var <span class="ident">m_StrideY</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor"><code class="flex name class">
<span>class <span class="ident">DetectionPostProcessDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the DetectionPostProcess layer. See <code><a title="pyarmnn.INetwork.AddDetectionPostProcessLayer" href="#pyarmnn.INetwork.AddDetectionPostProcessLayer">INetwork.AddDetectionPostProcessLayer()</a></code>.</p>
<p>This layer is a custom layer used to process the output from SSD MobilenetV1.</p>
<h2 id="contains">Contains</h2>
<p>m_MaxDetections (int): Underlying C++ data type is <code>uint32_t</code>. Maximum numbers of detections. Default: 0.
m_MaxClassesPerDetection (int): Underlying C++ data type is <code>uint32_t</code>. Maximum numbers of classes per detection, used in Fast NMS. Default: 1.
m_DetectionsPerClass (int): Underlying C++ data type is <code>uint32_t</code>. Detections per classes, used in Regular NMS. Default: 1.
m_NmsScoreThreshold (float): Non maximum suppression score threshold. Default: 0.
m_NmsIouThreshold (float): Intersection over union threshold. Default: 0.
m_NumClasses (int): Underlying C++ data type is <code>uint32_t</code>. Number of classes. Default: 0.
m_UseRegularNms (bool): Use Regular Non maximum suppression. Default: false.
m_ScaleX (float): Center size encoding scale x. Default: 0.
m_ScaleY (float): Center size encoding scale y. Default: 0.
m_ScaleW (float): Center size encoding scale weight. Default: 0.
m_ScaleH (float): Center size encoding scale height. Default: 0.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_DetectionsPerClass"><code class="name">var <span class="ident">m_DetectionsPerClass</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_MaxClassesPerDetection"><code class="name">var <span class="ident">m_MaxClassesPerDetection</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_MaxDetections"><code class="name">var <span class="ident">m_MaxDetections</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_NmsIouThreshold"><code class="name">var <span class="ident">m_NmsIouThreshold</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_NmsScoreThreshold"><code class="name">var <span class="ident">m_NmsScoreThreshold</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_NumClasses"><code class="name">var <span class="ident">m_NumClasses</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_ScaleH"><code class="name">var <span class="ident">m_ScaleH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_ScaleW"><code class="name">var <span class="ident">m_ScaleW</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_ScaleX"><code class="name">var <span class="ident">m_ScaleX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_ScaleY"><code class="name">var <span class="ident">m_ScaleY</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_UseRegularNms"><code class="name">var <span class="ident">m_UseRegularNms</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.FakeQuantizationDescriptor"><code class="flex name class">
<span>class <span class="ident">FakeQuantizationDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the FakeQuantization layer. See ``.</p>
<h2 id="contains">Contains</h2>
<p>m_Min (float): Minimum value for quantization range. Default: -6.0.
m_Max (float): Maximum value for quantization range. Default: 6.0.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.FakeQuantizationDescriptor.m_Max"><code class="name">var <span class="ident">m_Max</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.FakeQuantizationDescriptor.m_Min"><code class="name">var <span class="ident">m_Min</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.FakeQuantizationDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.FullyConnectedDescriptor"><code class="flex name class">
<span>class <span class="ident">FullyConnectedDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the FullyConnected layer. See <code><a title="pyarmnn.INetwork.AddFullyConnectedLayer" href="#pyarmnn.INetwork.AddFullyConnectedLayer">INetwork.AddFullyConnectedLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_BiasEnabled (bool): Enable/disable bias. Default: false.
m_TransposeWeightMatrix (bool): Enable/disable transpose weight matrix. Default: false.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.FullyConnectedDescriptor.m_BiasEnabled"><code class="name">var <span class="ident">m_BiasEnabled</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.FullyConnectedDescriptor.m_TransposeWeightMatrix"><code class="name">var <span class="ident">m_TransposeWeightMatrix</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.FullyConnectedDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ICaffeParser"><code class="flex name class">
<span>class <span class="ident">ICaffeParser</span></span>
</code></dt>
<dd>
<div class="desc"><p>Interface for creating a parser object using Caffe (<a href="http://caffe.berkeleyvision.org/">http://caffe.berkeleyvision.org/</a>) caffemodel files.</p>
<p>Parsers are used to automatically construct Arm NN graphs from model files.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ICaffeParser.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.ICaffeParser.CreateNetworkFromBinaryFile"><code class="name flex">
<span>def <span class="ident">CreateNetworkFromBinaryFile</span></span>(<span>self, graphFile, inputShapes, requestedOutputs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create the network from a Caffe caffemodel binary file on disk.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graphFile</code></strong></dt>
<dd>Path to the caffe model to be parsed.</dd>
<dt><strong><code>inputShapes</code></strong> :&ensp;<code>tuple</code></dt>
<dd>(<code>string</code>, <code><a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape">TensorShape</a></code>) A tuple containing the input name and TensorShape information for the network.</dd>
<dt><strong><code>requestedOutputs</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of the output tensor names.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork">INetwork</a></code></dt>
<dd>INetwork object for the parsed Caffe model.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ICaffeParser.GetNetworkInputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkInputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the input.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(<code>int</code>, <code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>)</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ICaffeParser.GetNetworkOutputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkOutputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the output.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(<code>int</code>, <code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>)</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IConnectableLayer"><code class="flex name class">
<span>class <span class="ident">IConnectableLayer</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Interface for a layer that is connectable to other layers via <code><a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot">IInputSlot</a></code> and <code><a title="pyarmnn.IOutputSlot" href="#pyarmnn.IOutputSlot">IOutputSlot</a></code>.
The object implementing this interface is returned by <code><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork">INetwork</a></code> when calling <code>add*Layer</code> methods.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IConnectableLayer.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IConnectableLayer.GetGuid"><code class="name flex">
<span>def <span class="ident">GetGuid</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the unique layer id (within one process).
Guid is generated and assigned automatically when the layer is created.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The unique layer id.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IConnectableLayer.GetInputSlot"><code class="name flex">
<span>def <span class="ident">GetInputSlot</span></span>(<span>self, index)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the input slot by index.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>index</code></strong> :&ensp;<code>int</code></dt>
<dd>Slot index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot">IInputSlot</a></code></dt>
<dd>Borrowed reference to input slot.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IConnectableLayer.GetName"><code class="name flex">
<span>def <span class="ident">GetName</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the name of the layer. Name attribute is optional for a layer, thus
<code>None</code> value could be returned.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Layer name or <code>None</code>.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IConnectableLayer.GetNumInputSlots"><code class="name flex">
<span>def <span class="ident">GetNumInputSlots</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the number of input slots for the layer.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of input slots.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IConnectableLayer.GetNumOutputSlots"><code class="name flex">
<span>def <span class="ident">GetNumOutputSlots</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the number of output slots for the layer.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of output slots.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IConnectableLayer.GetOutputSlot"><code class="name flex">
<span>def <span class="ident">GetOutputSlot</span></span>(<span>self, index)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the output slot by index.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>index</code></strong> :&ensp;<code>int</code></dt>
<dd>Slot index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IOutputSlot" href="#pyarmnn.IOutputSlot">IOutputSlot</a></code></dt>
<dd>Borrowed reference to output slot.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IDeviceSpec"><code class="flex name class">
<span>class <span class="ident">IDeviceSpec</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Interface for device specifications. Main use is to get information relating to what compute capability the device being used has.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IDeviceSpec.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IDeviceSpec.GetSupportedBackends"><code class="name flex">
<span>def <span class="ident">GetSupportedBackends</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the backends supported by this compute device.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>set</code></dt>
<dd>This devices supported backends.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IInputSlot"><code class="flex name class">
<span>class <span class="ident">IInputSlot</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>An input connection slot for a layer. Slot lifecycle is managed by the layer.</p>
<p>The input slot can be connected to an output slot of the preceding layer in the graph.
Only one connection to the input slot is allowed.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IInputSlot.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IInputSlot.GetConnection"><code class="name flex">
<span>def <span class="ident">GetConnection</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns output slot of a preceding layer that is connected to the given input slot.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IOutputSlot" href="#pyarmnn.IOutputSlot">IOutputSlot</a></code></dt>
<dd>Borrowed reference to an output connection slot for a preceding layer.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.INetwork"><code class="flex name class">
<span>class <span class="ident">INetwork</span></span>
</code></dt>
<dd>
<div class="desc"><p>Interface for a network object. Network objects contain the whole computation graph, made up of different layers connected together.</p>
<p>INetwork objects can be constructed manually or obtained by using parsers. INetwork objects are used to create optimized networks, see <code><a title="pyarmnn.Optimize" href="#pyarmnn.Optimize">Optimize()</a></code>.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.INetwork.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.INetwork.AddActivationLayer"><code class="name flex">
<span>def <span class="ident">AddActivationLayer</span></span>(<span>self, activationDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds an Activation layer to the network. Type of activation is decided by activationDescriptor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>activationDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.ActivationDescriptor" href="#pyarmnn.ActivationDescriptor">ActivationDescriptor</a></code></dt>
<dd>ActivationDescriptor to configure the activation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddAdditionLayer"><code class="name flex">
<span>def <span class="ident">AddAdditionLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds an addition layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddBatchNormalizationLayer"><code class="name flex">
<span>def <span class="ident">AddBatchNormalizationLayer</span></span>(<span>self, desc, mean, variance, beta, gamma, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Batch Normalization layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>mean</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Pre-calculated mean for each channel.</dd>
<dt><strong><code>variance</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Pre-calculated variance for each channel.</dd>
<dt><strong><code>beta</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Per-channel additive factor.</dd>
<dt><strong><code>gamma</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Per-channel multiplicative factor.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddBatchToSpaceNdLayer"><code class="name flex">
<span>def <span class="ident">AddBatchToSpaceNdLayer</span></span>(<span>self, batchToSpaceNdDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Batch To Space ND layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>batchToSpaceNdDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.BatchToSpaceNdDescriptor" href="#pyarmnn.BatchToSpaceNdDescriptor">BatchToSpaceNdDescriptor</a></code></dt>
<dd>Configuration parameters for the layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddConcatLayer"><code class="name flex">
<span>def <span class="ident">AddConcatLayer</span></span>(<span>self, concatDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Concatenation layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>concatDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.ConcatDescriptor" href="#pyarmnn.ConcatDescriptor">ConcatDescriptor</a></code></dt>
<dd>Parameters to configure the Concatenation layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddConstantLayer"><code class="name flex">
<span>def <span class="ident">AddConstantLayer</span></span>(<span>self, input, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a layer with no inputs and a single output, which always corresponds to the passed in constant tensor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Tensor to be provided as the only output of the layer. The layer will maintain
its own copy of the tensor data, meaning the memory referenced by input can
be freed or reused after this function is called.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddConvolution2dLayer"><code class="name flex">
<span>def <span class="ident">AddConvolution2dLayer</span></span>(<span>self, convolution2dDescriptor, weights, biases=None, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a 2D Convolution layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>convolution2dDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.Convolution2dDescriptor" href="#pyarmnn.Convolution2dDescriptor">Convolution2dDescriptor</a></code></dt>
<dd>Description of the 2D convolution layer.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Tensor for the weights data.</dd>
<dt><strong><code>biases</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Optional tensor for the bias data. If specified, must match the output tensor shape.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddDepthwiseConvolution2dLayer"><code class="name flex">
<span>def <span class="ident">AddDepthwiseConvolution2dLayer</span></span>(<span>self, convolution2dDescriptor, weights, biases=None, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a 2D Depthwise Convolution layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>convolution2dDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.DepthwiseConvolution2dDescriptor" href="#pyarmnn.DepthwiseConvolution2dDescriptor">DepthwiseConvolution2dDescriptor</a></code></dt>
<dd>Description of the 2D depthwise convolution layer.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Tensor for the weights. Expected format: [channelMultiplier, inputChannels, height, width].</dd>
<dt><strong><code>biases</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Optional tensor for the bias data. If specified, must match the output tensor shape.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddDequantizeLayer"><code class="name flex">
<span>def <span class="ident">AddDequantizeLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Dequantize layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddDetectionPostProcessLayer"><code class="name flex">
<span>def <span class="ident">AddDetectionPostProcessLayer</span></span>(<span>self, descriptor, anchors, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Detection PostProcess layer to the network. Detection PostProcess is a custom layer for SSD MobilenetV1.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>descriptor</code></strong> :&ensp;<code><a title="pyarmnn.DetectionPostProcessDescriptor" href="#pyarmnn.DetectionPostProcessDescriptor">DetectionPostProcessDescriptor</a></code></dt>
<dd>Description of the Detection PostProcess layer.</dd>
<dt><strong><code>anchors</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Tensor for anchors.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddDivisionLayer"><code class="name flex">
<span>def <span class="ident">AddDivisionLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Division layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddFloorLayer"><code class="name flex">
<span>def <span class="ident">AddFloorLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Floor layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddFullyConnectedLayer"><code class="name flex">
<span>def <span class="ident">AddFullyConnectedLayer</span></span>(<span>self, fullyConnectedDescriptor, weights, biases=None, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Fully Connected layer to the network. Also known as a Linear or Dense layer.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fullyConnectedDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.FullyConnectedDescriptor" href="#pyarmnn.FullyConnectedDescriptor">FullyConnectedDescriptor</a></code></dt>
<dd>Description of the fully connected layer.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Tensor for the weights data.</dd>
<dt><strong><code>biases</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Optional tensor for the bias data.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddGatherLayer"><code class="name flex">
<span>def <span class="ident">AddGatherLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Add Gather layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddInputLayer"><code class="name flex">
<span>def <span class="ident">AddInputLayer</span></span>(<span>self, id, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds an input layer to the network. Input layers are placed at the start of a network and used for feeding input data during inference.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>id</code></strong> :&ensp;<code>int</code></dt>
<dd>User generated id to uniquely identify a particular input. The same id needs to be specified
when passing the inputs to the IRuntime::EnqueueWorkload() function.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddL2NormalizationLayer"><code class="name flex">
<span>def <span class="ident">AddL2NormalizationLayer</span></span>(<span>self, desc, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds an L2 Normalization layer to the network.
Normalization is performed along dimension 1, but requires a 4d input.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>desc</code></strong> :&ensp;<code><a title="pyarmnn.L2NormalizationDescriptor" href="#pyarmnn.L2NormalizationDescriptor">L2NormalizationDescriptor</a></code></dt>
<dd>Parameters for the L2 normalization operation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddLstmLayer"><code class="name flex">
<span>def <span class="ident">AddLstmLayer</span></span>(<span>self, descriptor, params, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a Long Short-Term Memory layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>descriptor</code></strong> :&ensp;<code><a title="pyarmnn.LstmDescriptor" href="#pyarmnn.LstmDescriptor">LstmDescriptor</a></code></dt>
<dd>Parameters for the Lstm operation.</dd>
<dt><strong><code>params</code></strong> :&ensp;<code><a title="pyarmnn.LstmInputParams" href="#pyarmnn.LstmInputParams">LstmInputParams</a></code></dt>
<dd>Weights and biases for the LSTM cell.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddMaximumLayer"><code class="name flex">
<span>def <span class="ident">AddMaximumLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a Maximum layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddMeanLayer"><code class="name flex">
<span>def <span class="ident">AddMeanLayer</span></span>(<span>self, meanDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Mean layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>meanDescriptor</code></strong> :&ensp;<code>meanDescriptor</code></dt>
<dd>Parameters for the mean operation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddMergeLayer"><code class="name flex">
<span>def <span class="ident">AddMergeLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Merge layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddMinimumLayer"><code class="name flex">
<span>def <span class="ident">AddMinimumLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Minimum layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddMultiplicationLayer"><code class="name flex">
<span>def <span class="ident">AddMultiplicationLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Multiplication layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddNormalizationLayer"><code class="name flex">
<span>def <span class="ident">AddNormalizationLayer</span></span>(<span>self, normalizationDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Normalization layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>normalizationDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.NormalizationDescriptor" href="#pyarmnn.NormalizationDescriptor">NormalizationDescriptor</a></code></dt>
<dd>Parameters to configure the normalization.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddOutputLayer"><code class="name flex">
<span>def <span class="ident">AddOutputLayer</span></span>(<span>self, id, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds an output layer to the network. Output layer is the final layer in your network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>id</code></strong> :&ensp;<code>int</code></dt>
<dd>User generated id to uniquely identify a particular input. The same id needs to be specified
when passing the inputs to <code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">IRuntime.EnqueueWorkload()</a></code>.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<p>Returns:
IConnectableLayer: Interface for configuring the layer.</p></div>
</dd>
<dt id="pyarmnn.INetwork.AddPadLayer"><code class="name flex">
<span>def <span class="ident">AddPadLayer</span></span>(<span>self, padDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Pad layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>padDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.PadDescriptor" href="#pyarmnn.PadDescriptor">PadDescriptor</a></code></dt>
<dd>Padding configuration for the layer. See <code><a title="pyarmnn.PadDescriptor" href="#pyarmnn.PadDescriptor">PadDescriptor</a></code> for more details.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddPermuteLayer"><code class="name flex">
<span>def <span class="ident">AddPermuteLayer</span></span>(<span>self, permuteDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Permute layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>permuteDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.PermuteDescriptor" href="#pyarmnn.PermuteDescriptor">PermuteDescriptor</a></code></dt>
<dd>Configuration of the permutation layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddPooling2dLayer"><code class="name flex">
<span>def <span class="ident">AddPooling2dLayer</span></span>(<span>self, pooling2dDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Pooling layer to the network. Type of pooling is decided by the configuration.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>pooling2dDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.Pooling2dDescriptor" href="#pyarmnn.Pooling2dDescriptor">Pooling2dDescriptor</a></code></dt>
<dd>Configuration for the pooling layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddPreluLayer"><code class="name flex">
<span>def <span class="ident">AddPreluLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a PReLU layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddQuantizeLayer"><code class="name flex">
<span>def <span class="ident">AddQuantizeLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Quantize layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddQuantizedLstmLayer"><code class="name flex">
<span>def <span class="ident">AddQuantizedLstmLayer</span></span>(<span>self, params, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Quantized Long Short-Term Memory layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>QuantizedLstmInputParams</code></dt>
<dd>The weights and biases for the Quantized LSTM cell.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddReshapeLayer"><code class="name flex">
<span>def <span class="ident">AddReshapeLayer</span></span>(<span>self, reshapeDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Reshape layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>reshapeDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.ReshapeDescriptor" href="#pyarmnn.ReshapeDescriptor">ReshapeDescriptor</a></code></dt>
<dd>Parameters for the reshape operation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddResizeLayer"><code class="name flex">
<span>def <span class="ident">AddResizeLayer</span></span>(<span>self, resizeDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Resize layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>resizeDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.ResizeDescriptor" href="#pyarmnn.ResizeDescriptor">ResizeDescriptor</a></code></dt>
<dd>Configuration for the resize layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddRsqrtLayer"><code class="name flex">
<span>def <span class="ident">AddRsqrtLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds Reciprocal of square root layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddSoftmaxLayer"><code class="name flex">
<span>def <span class="ident">AddSoftmaxLayer</span></span>(<span>self, softmaxDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Softmax layer to the network.</p>
<p>If the data type is <code>DataType_QuantisedAsymm8</code>, then the output quantization parameters
must have a scale of 1/256 and an offset of 0.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>softmaxDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.SoftmaxDescriptor" href="#pyarmnn.SoftmaxDescriptor">SoftmaxDescriptor</a></code></dt>
<dd>Configuration for the softmax layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddSpaceToBatchNdLayer"><code class="name flex">
<span>def <span class="ident">AddSpaceToBatchNdLayer</span></span>(<span>self, spaceToBatchNdDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Space To Batch layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>spaceToBatchNdDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.SpaceToBatchNdDescriptor" href="#pyarmnn.SpaceToBatchNdDescriptor">SpaceToBatchNdDescriptor</a></code></dt>
<dd>Configuration for the space to batch layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddSpaceToDepthLayer"><code class="name flex">
<span>def <span class="ident">AddSpaceToDepthLayer</span></span>(<span>self, spaceToDepthDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a space to depth layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>spaceToDepthDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.SpaceToDepthDescriptor" href="#pyarmnn.SpaceToDepthDescriptor">SpaceToDepthDescriptor</a></code></dt>
<dd>Parameters for the space to depth operation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddSplitterLayer"><code class="name flex">
<span>def <span class="ident">AddSplitterLayer</span></span>(<span>self, splitterDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Splitter layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>splitterDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.SplitterDescriptor" href="#pyarmnn.SplitterDescriptor">SplitterDescriptor</a></code></dt>
<dd>Parameters to configure the splitter layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddStackLayer"><code class="name flex">
<span>def <span class="ident">AddStackLayer</span></span>(<span>self, descriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Stack layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>descriptor</code></strong> :&ensp;<code><a title="pyarmnn.StackDescriptor" href="#pyarmnn.StackDescriptor">StackDescriptor</a></code></dt>
<dd>Descriptor to configure the stack layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddStridedSliceLayer"><code class="name flex">
<span>def <span class="ident">AddStridedSliceLayer</span></span>(<span>self, stridedSliceDescriptor, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Strided Slice layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>stridedSliceDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.StridedSliceDescriptor" href="#pyarmnn.StridedSliceDescriptor">StridedSliceDescriptor</a></code></dt>
<dd>Parameters for the strided slice operation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddSubtractionLayer"><code class="name flex">
<span>def <span class="ident">AddSubtractionLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Subtraction layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddSwitchLayer"><code class="name flex">
<span>def <span class="ident">AddSwitchLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a Switch layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.INetwork.AddTransposeConvolution2dLayer"><code class="name flex">
<span>def <span class="ident">AddTransposeConvolution2dLayer</span></span>(<span>self, descriptor, weights, biases=None, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a 2D Transpose Convolution layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>descriptor</code></strong> :&ensp;<code><a title="pyarmnn.TransposeConvolution2dDescriptor" href="#pyarmnn.TransposeConvolution2dDescriptor">TransposeConvolution2dDescriptor</a></code></dt>
<dd>Descriptor containing all parameters to configure this layer.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Tensor for the weights data.</dd>
<dt><strong><code>biases</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Optional tensor for the bias data.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IOnnxParser"><code class="flex name class">
<span>class <span class="ident">IOnnxParser</span></span>
</code></dt>
<dd>
<div class="desc"><p>Interface for creating a parser object using ONNX (<a href="https://onnx.ai/">https://onnx.ai/</a>) onnx files.</p>
<p>Parsers are used to automatically construct Arm NN graphs from model files.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IOnnxParser.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IOnnxParser.CreateNetworkFromBinaryFile"><code class="name flex">
<span>def <span class="ident">CreateNetworkFromBinaryFile</span></span>(<span>self, graphFile)</span>
</code></dt>
<dd>
<div class="desc"><p>Create the network from a binary file on disk.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graphFile</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the onnx model to be parsed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork">INetwork</a></code></dt>
<dd>Parsed network.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If model file was not found.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IOnnxParser.GetNetworkInputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkInputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>string</code></dt>
<dd>Name of the input node.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(<code>int</code>, <code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>)</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IOnnxParser.GetNetworkOutputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkOutputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>string</code></dt>
<dd>Name of the output node.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(<code>int</code>, <code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>)</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IOptimizedNetwork"><code class="flex name class">
<span>class <span class="ident">IOptimizedNetwork</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Interface class for an optimzied network object. Optimized networks are obtained after running <code><a title="pyarmnn.Optimize" href="#pyarmnn.Optimize">Optimize()</a></code> on
an <code><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork">INetwork</a></code> object.
Optimized networks are passed to <code>EnqueueWorkload</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>convolution2dDescriptor</code></strong> :&ensp;<code><a title="pyarmnn.DepthwiseConvolution2dDescriptor" href="#pyarmnn.DepthwiseConvolution2dDescriptor">DepthwiseConvolution2dDescriptor</a></code></dt>
<dd>Description of the 2D depthwise convolution layer.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Tensor for the weights. Expected format: [channelMultiplier, inputChannels, height, width].</dd>
<dt><strong><code>biases</code></strong> :&ensp;<code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></dt>
<dd>Optional tensor for the bias data. If specified, must match the output tensor shape.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></dt>
<dd>Interface for configuring the layer.</dd>
</dl></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IOptimizedNetwork.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IOptimizedNetwork.SerializeToDot"><code class="name flex">
<span>def <span class="ident">SerializeToDot</span></span>(<span>self, fileName)</span>
</code></dt>
<dd>
<div class="desc"><p>Saves optimized network graph as dot file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fileName</code></strong> :&ensp;<code>str</code></dt>
<dd>File path to save to.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If serialization failure.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IOutputSlot"><code class="flex name class">
<span>class <span class="ident">IOutputSlot</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>An output connection slot for a layer. Slot lifecycle is managed by the layer.</p>
<p>The output slot may be connected to 1 or more input slots of subsequent layers in the graph.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IOutputSlot.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IOutputSlot.CalculateIndexOnOwner"><code class="name flex">
<span>def <span class="ident">CalculateIndexOnOwner</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the index of this slot for the layer.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Slot index.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IOutputSlot.Connect"><code class="name flex">
<span>def <span class="ident">Connect</span></span>(<span>self, destination)</span>
</code></dt>
<dd>
<div class="desc"><p>Connects this output slot with given input slot.
Input slot is updated with this output connection.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>destination</code></strong> :&ensp;<code><a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot">IInputSlot</a></code></dt>
<dd>Output tensor info.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Total number of connections.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If input slot was already connected.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IOutputSlot.Disconnect"><code class="name flex">
<span>def <span class="ident">Disconnect</span></span>(<span>self, slot)</span>
</code></dt>
<dd>
<div class="desc"><p>Disconnects this output slot from given input slot.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>slot</code></strong> :&ensp;<code><a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot">IInputSlot</a></code></dt>
<dd>Input slot to disconnect from.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IOutputSlot.GetConnection"><code class="name flex">
<span>def <span class="ident">GetConnection</span></span>(<span>self, index)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieves connected input slot by index.</p>
<p>The same result could be obtained by using square brackets:</p>
<pre><code class="python">&gt;&gt;&gt; output_slot = ...
&gt;&gt;&gt; connected_input_slot = output_slot[0]
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>index</code></strong> :&ensp;<code>int</code></dt>
<dd>Slot index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot">IInputSlot</a></code></dt>
<dd>Borrowed reference to connected input slot with given index.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If index out of bounds.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IOutputSlot.GetNumConnections"><code class="name flex">
<span>def <span class="ident">GetNumConnections</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the total number of connected input slots.</p>
<p>The same result could be obtained by calling <code>len()</code>:</p>
<pre><code class="python">&gt;&gt;&gt; output_slot = ...
&gt;&gt;&gt; size = len(output_slot)
&gt;&gt;&gt; assert size == output_slot.GetNumConnections()
</code></pre>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of connected input slots.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IOutputSlot.GetOwningLayerGuid"><code class="name flex">
<span>def <span class="ident">GetOwningLayerGuid</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the index of the layer. Same value as <code><a title="pyarmnn.IConnectableLayer.GetGuid" href="#pyarmnn.IConnectableLayer.GetGuid">IConnectableLayer.GetGuid()</a></code>.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Layer id.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IOutputSlot.GetTensorInfo"><code class="name flex">
<span>def <span class="ident">GetTensorInfo</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets tensor info for output slot.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tensorInfo</code></strong> :&ensp;<code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code></dt>
<dd>Output tensor info.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IOutputSlot.IsTensorInfoSet"><code class="name flex">
<span>def <span class="ident">IsTensorInfoSet</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if tensor info was set previously.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if output tensor info was set, False - otherwise.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IOutputSlot.SetTensorInfo"><code class="name flex">
<span>def <span class="ident">SetTensorInfo</span></span>(<span>self, tensorInfo)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets tensor info for output slot.
Operation does not change TensorInfo ownership.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tensorInfo</code></strong> :&ensp;<code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code></dt>
<dd>Output tensor info.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IProfiler"><code class="flex name class">
<span>class <span class="ident">IProfiler</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Interface for profiling Arm NN. See <code><a title="pyarmnn.IRuntime.GetProfiler" href="#pyarmnn.IRuntime.GetProfiler">IRuntime.GetProfiler()</a></code>.</p>
<p>IProfiler object allows you to enable profiling and get various profiling results.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IProfiler.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IProfiler.EnableProfiling"><code class="name flex">
<span>def <span class="ident">EnableProfiling</span></span>(<span>self, enableProfiling)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the profiler to start/stop profiling.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>enableProfiling</code></strong> :&ensp;<code>bool</code></dt>
<dd>Flag to enable/disable profiling.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IProfiler.IsProfilingEnabled"><code class="name flex">
<span>def <span class="ident">IsProfilingEnabled</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if profiling is enabled.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>If profiling is enabled or not.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IProfiler.as_json"><code class="name flex">
<span>def <span class="ident">as_json</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the profiling log as the JSON string.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Profiling log as JSON formatted string.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IProfiler.event_log"><code class="name flex">
<span>def <span class="ident">event_log</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the string value of the profiling events analysis log.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The profiling events analysis log.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IRuntime"><code class="flex name class">
<span>class <span class="ident">IRuntime</span></span>
<span>(</span><span>options)</span>
</code></dt>
<dd>
<div class="desc"><p>Interface for runtime objects.</p>
<p>Runtime objects are responsible for performing inference on an <code><a title="pyarmnn.IOptimizedNetwork" href="#pyarmnn.IOptimizedNetwork">IOptimizedNetwork</a></code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>options</code></strong> :&ensp;<code><a title="pyarmnn.CreationOptions" href="#pyarmnn.CreationOptions">CreationOptions</a></code></dt>
<dd>CreationOptions data struct.</dd>
</dl></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IRuntime.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IRuntime.EnqueueWorkload"><code class="name flex">
<span>def <span class="ident">EnqueueWorkload</span></span>(<span>self, networkId, inputTensors, outputTensors)</span>
</code></dt>
<dd>
<div class="desc"><p>Calling this function will perform an inference on your network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>networkId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the network to run.</dd>
<dt><strong><code>inputTensors</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of tuples (int, ConstTensor), see <code><a title="pyarmnn.make_input_tensors" href="#pyarmnn.make_input_tensors">make_input_tensors()</a></code>.</dd>
<dt><strong><code>outputTensors</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of tuples (int, Tensor), see <code><a title="pyarmnn.make_output_tensors" href="#pyarmnn.make_output_tensors">make_output_tensors()</a></code>.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IRuntime.GetDeviceSpec"><code class="name flex">
<span>def <span class="ident">GetDeviceSpec</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get information relating supported compute backends on current device.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IDeviceSpec" href="#pyarmnn.IDeviceSpec">IDeviceSpec</a></code></dt>
<dd>Device spec information detailing all supported backends on current platform.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IRuntime.GetInputTensorInfo"><code class="name flex">
<span>def <span class="ident">GetInputTensorInfo</span></span>(<span>self, networkId, layerId)</span>
</code></dt>
<dd>
<div class="desc"><p>Get information relating to networks input tensor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>networkId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the network being run.</dd>
<dt><strong><code>layerId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the input layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code></dt>
<dd>Information relating to the input tensor a network.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IRuntime.GetOutputTensorInfo"><code class="name flex">
<span>def <span class="ident">GetOutputTensorInfo</span></span>(<span>self, networkId, layerId)</span>
</code></dt>
<dd>
<div class="desc"><p>Get information relating to networks output tensor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>networkId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the network being run.</dd>
<dt><strong><code>layerId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the output layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code></dt>
<dd>Information relating to the output tensor a network.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IRuntime.GetProfiler"><code class="name flex">
<span>def <span class="ident">GetProfiler</span></span>(<span>self, networkId)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the IProfiler instance registered against the working thread, and stored on the loaded network.
Be aware that if the runtime has Unloaded the network, or if the runtime is destroyed,
that the IProfiler instance will also be destroyed, and will cause a segmentation fault.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>networkId</code></strong> :&ensp;<code>int</code></dt>
<dd>The ID of the loaded network you want to profile.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.IProfiler" href="#pyarmnn.IProfiler">IProfiler</a></code></dt>
<dd>IProfiler instance the given loaded network has stored.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If no profiler is found.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IRuntime.LoadNetwork"><code class="name flex">
<span>def <span class="ident">LoadNetwork</span></span>(<span>self, network)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads a complete network into the IRuntime.
The runtime takes ownership of the network once passed in.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>network</code></strong> :&ensp;<code><a title="pyarmnn.IOptimizedNetwork" href="#pyarmnn.IOptimizedNetwork">IOptimizedNetwork</a></code></dt>
<dd>An optimized network to load into the IRuntime.</dd>
<dt><strong><code>networkProperties</code></strong> :&ensp;<code>INetworkProperties</code></dt>
<dd>Properties that allows the user to opt-in to import/export behavior. Default: None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(int, str) Network id and non fatal failure or warning messsages.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If process fails.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.IRuntime.UnloadNetwork"><code class="name flex">
<span>def <span class="ident">UnloadNetwork</span></span>(<span>self, networkId)</span>
</code></dt>
<dd>
<div class="desc"><p>Unload a currently loaded network from the runtime.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>networkId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the network to unload.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ITfLiteParser"><code class="flex name class">
<span>class <span class="ident">ITfLiteParser</span></span>
</code></dt>
<dd>
<div class="desc"><p>Interface for creating a parser object using TfLite (<a href="https://www.tensorflow.org/lite">https://www.tensorflow.org/lite</a>) tflite files.</p>
<p>Parsers are used to automatically construct Arm NN graphs from model files.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ITfLiteParser.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.ITfLiteParser.CreateNetworkFromBinaryFile"><code class="name flex">
<span>def <span class="ident">CreateNetworkFromBinaryFile</span></span>(<span>self, graphFile)</span>
</code></dt>
<dd>
<div class="desc"><p>Create the network from a flatbuffers binary file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graphFile</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the tflite model to be parsed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork">INetwork</a></code></dt>
<dd>Parsed network.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If model file was not found.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ITfLiteParser.GetNetworkInputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkInputBindingInfo</span></span>(<span>self, subgraphId, name)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name and subgraph id.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>subgraphId</code></strong> :&ensp;<code>int</code></dt>
<dd>The subgraph id.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the input.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(<code>int</code>, <code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>).</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ITfLiteParser.GetNetworkOutputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkOutputBindingInfo</span></span>(<span>self, subgraphId, name)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name and subgraph id.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>subgraphId</code></strong> :&ensp;<code>int</code></dt>
<dd>The subgraphID.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the output.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(<code>int</code>, <code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>).</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ITfLiteParser.GetSubgraphCount"><code class="name flex">
<span>def <span class="ident">GetSubgraphCount</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the number of subgraphs in the parsed model.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The number of subgraphs.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ITfLiteParser.GetSubgraphInputTensorNames"><code class="name flex">
<span>def <span class="ident">GetSubgraphInputTensorNames</span></span>(<span>self, subgraphId)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the input tensor names for a given subgraph.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>subgraphId</code></strong> :&ensp;<code>int</code></dt>
<dd>The subgraph id.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>A list of the input tensor names for the given model.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ITfLiteParser.GetSubgraphOutputTensorNames"><code class="name flex">
<span>def <span class="ident">GetSubgraphOutputTensorNames</span></span>(<span>self, subgraphId)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the output tensor names for a given subgraph.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>subgraphId</code></strong> :&ensp;<code>int</code></dt>
<dd>The subgraph id</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>A list of the output tensor names for the given model.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ITfParser"><code class="flex name class">
<span>class <span class="ident">ITfParser</span></span>
</code></dt>
<dd>
<div class="desc"><p>Interface for creating a parser object using TensorFlow (<a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a>) frozen pb files.</p>
<p>Parsers are used to automatically construct Arm NN graphs from model files.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ITfParser.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.ITfParser.CreateNetworkFromBinaryFile"><code class="name flex">
<span>def <span class="ident">CreateNetworkFromBinaryFile</span></span>(<span>self, graphFile, inputShapes, requestedOutputs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create the network from a pb Protocol buffer file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graphFile</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the tf model to be parsed.</dd>
<dt><strong><code>inputShapes</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dict containing the input name as a key &amp; TensorShape as a value.</dd>
<dt><strong><code>requestedOutputs</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>A list of the output tensor names.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork">INetwork</a></code></dt>
<dd>Parsed network.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If model file was not found.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ITfParser.GetNetworkInputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkInputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the input.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(<code>int</code>, <code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>).</dd>
</dl></div>
</dd>
<dt id="pyarmnn.ITfParser.GetNetworkOutputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkOutputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the output.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(<code>int</code>, <code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>).</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.L2NormalizationDescriptor"><code class="flex name class">
<span>class <span class="ident">L2NormalizationDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A Descriptor for the L2Normalization layer. See <code><a title="pyarmnn.INetwork.AddL2NormalizationLayer" href="#pyarmnn.INetwork.AddL2NormalizationLayer">INetwork.AddL2NormalizationLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_Eps (float): Used to avoid dividing by zero.. Default: 1e-12f.
m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.L2NormalizationDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.L2NormalizationDescriptor.m_Eps"><code class="name">var <span class="ident">m_Eps</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.L2NormalizationDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.LstmDescriptor"><code class="flex name class">
<span>class <span class="ident">LstmDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the LSTM layer. See <code><a title="pyarmnn.INetwork.AddLstmLayer" href="#pyarmnn.INetwork.AddLstmLayer">INetwork.AddLstmLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_ActivationFunc (int): Underlying C++ data type is <code>uint32_t</code>. The activation function to use. 0: None, 1: Relu, 3: Relu6, 4: Tanh, 6: Sigmoid.
Default: 1.
m_ClippingThresCell (float): Clipping threshold value for the cell state. Default: 0.0.
m_ClippingThresProj (float): Clipping threshold value for the projection. Default: 0.0.
m_CifgEnabled (bool): Enable/disable cifg (coupled input &amp; forget gate). Default: true.
m_PeepholeEnabled (bool): Enable/disable peephole. Default: false.
m_ProjectionEnabled (bool): Enable/disable the projection layer. Default: false.
m_LayerNormEnabled (bool): Enable/disable layer normalization. Default: false.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.LstmDescriptor.m_ActivationFunc"><code class="name">var <span class="ident">m_ActivationFunc</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_CifgEnabled"><code class="name">var <span class="ident">m_CifgEnabled</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_ClippingThresCell"><code class="name">var <span class="ident">m_ClippingThresCell</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_ClippingThresProj"><code class="name">var <span class="ident">m_ClippingThresProj</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_LayerNormEnabled"><code class="name">var <span class="ident">m_LayerNormEnabled</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_PeepholeEnabled"><code class="name">var <span class="ident">m_PeepholeEnabled</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_ProjectionEnabled"><code class="name">var <span class="ident">m_ProjectionEnabled</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.LstmInputParams"><code class="flex name class">
<span>class <span class="ident">LstmInputParams</span></span>
</code></dt>
<dd>
<div class="desc"><p>Long Short-Term Memory layer input parameters.</p>
<p>See <code><a title="pyarmnn.INetwork.AddLstmLayer" href="#pyarmnn.INetwork.AddLstmLayer">INetwork.AddLstmLayer()</a></code>.
Operation described by the following equations:</p>
<p><span><span class="MathJax_Preview">i_t=\sigma(W_{xi}x_t+W_{hi}h_{t-1}+W_{ci}C_{t-1}+b_i) \\
f_t=\sigma(W_{xf}x_t+W_{hf}h_{t-1}+W_{cf}C_{t-1}+b_f) \\
C_t=clip(f_t \odot C_{t-1} + i_t \odot g(W_{xc}x_t+W_{hc}h_{t-1}+b_c),\ t_{cell}) \\
o_t = \sigma(W_{xo}x_t+W_{ho}h_{t-1}+W_{co}C_t+b_o)
\\
h_t = clip(W_{proj}(o_t \odot g(C_t))+b_{proj},\ t_{proj})\ if\ there\ is\ a\ projection;
\\
h_t = o_t \odot g(C_t)\ otherwise. </span><script type="math/tex; mode=display">i_t=\sigma(W_{xi}x_t+W_{hi}h_{t-1}+W_{ci}C_{t-1}+b_i) \\
f_t=\sigma(W_{xf}x_t+W_{hf}h_{t-1}+W_{cf}C_{t-1}+b_f) \\
C_t=clip(f_t \odot C_{t-1} + i_t \odot g(W_{xc}x_t+W_{hc}h_{t-1}+b_c),\ t_{cell}) \\
o_t = \sigma(W_{xo}x_t+W_{ho}h_{t-1}+W_{co}C_t+b_o)
\\
h_t = clip(W_{proj}(o_t \odot g(C_t))+b_{proj},\ t_{proj})\ if\ there\ is\ a\ projection;
\\
h_t = o_t \odot g(C_t)\ otherwise. </script></span>
Where:
<span><span class="MathJax_Preview">x_t</span><script type="math/tex">x_t</script></span> - input;
<span><span class="MathJax_Preview">i_t</span><script type="math/tex">i_t</script></span> - input gate;
<span><span class="MathJax_Preview">f_t</span><script type="math/tex">f_t</script></span> - forget gate;
<span><span class="MathJax_Preview">C_t</span><script type="math/tex">C_t</script></span> - cell state;
<span><span class="MathJax_Preview">o_t</span><script type="math/tex">o_t</script></span> - output;
<span><span class="MathJax_Preview">h_t</span><script type="math/tex">h_t</script></span> - output state;
<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span> - logistic sigmoid function;
<span><span class="MathJax_Preview">g</span><script type="math/tex">g</script></span> - cell input and cell output activation function, see <code><a title="pyarmnn.LstmDescriptor.m_ActivationFunc" href="#pyarmnn.LstmDescriptor.m_ActivationFunc">LstmDescriptor.m_ActivationFunc</a></code>;
<span><span class="MathJax_Preview">t_{cell}</span><script type="math/tex">t_{cell}</script></span> - threshold for clipping the cell state, see <code><a title="pyarmnn.LstmDescriptor.m_ClippingThresCell" href="#pyarmnn.LstmDescriptor.m_ClippingThresCell">LstmDescriptor.m_ClippingThresCell</a></code>;
<span><span class="MathJax_Preview">t_{proj}</span><script type="math/tex">t_{proj}</script></span> - threshold for clipping the projected output, see <code><a title="pyarmnn.LstmDescriptor.m_ClippingThresProj" href="#pyarmnn.LstmDescriptor.m_ClippingThresProj">LstmDescriptor.m_ClippingThresProj</a></code>;</p>
<h2 id="contains">Contains</h2>
<p>m_InputToInputWeights (ConstTensor): <span><span class="MathJax_Preview">W_{xi}</span><script type="math/tex">W_{xi}</script></span>, input-to-input weight matrix.
m_InputToForgetWeights (ConstTensor): <span><span class="MathJax_Preview">W_{xf}</span><script type="math/tex">W_{xf}</script></span>, input-to-forget weight matrix.
m_InputToCellWeights (ConstTensor): <span><span class="MathJax_Preview">W_{xc}</span><script type="math/tex">W_{xc}</script></span>, input-to-cell weight matrix.
m_InputToOutputWeights (ConstTensor): <span><span class="MathJax_Preview">W_{xo}</span><script type="math/tex">W_{xo}</script></span>, input-to-output weight matrix.</p>
<p>m_RecurrentToInputWeights (ConstTensor): <span><span class="MathJax_Preview">W_{hi}</span><script type="math/tex">W_{hi}</script></span>, recurrent-to-input weight matrix.
m_RecurrentToForgetWeights (ConstTensor): <span><span class="MathJax_Preview">W_{hf}</span><script type="math/tex">W_{hf}</script></span>, recurrent-to-forget weight matrix.
m_RecurrentToCellWeights (ConstTensor): <span><span class="MathJax_Preview">W_{hc}</span><script type="math/tex">W_{hc}</script></span>, recurrent-to-cell weight matrix.
m_RecurrentToOutputWeights (ConstTensor): <span><span class="MathJax_Preview">W_{ho}</span><script type="math/tex">W_{ho}</script></span>, recurrent-to-output weight matrix.</p>
<p>m_CellToInputWeights (ConstTensor): <span><span class="MathJax_Preview">W_{ci}</span><script type="math/tex">W_{ci}</script></span>, cell-to-input weight matrix. Has effect if <code><a title="pyarmnn.LstmDescriptor.m_PeepholeEnabled" href="#pyarmnn.LstmDescriptor.m_PeepholeEnabled">LstmDescriptor.m_PeepholeEnabled</a></code>.
m_CellToForgetWeights (ConstTensor): <span><span class="MathJax_Preview">W_{cf}</span><script type="math/tex">W_{cf}</script></span>, cell-to-forget weight matrix. Has effect if <code><a title="pyarmnn.LstmDescriptor.m_PeepholeEnabled" href="#pyarmnn.LstmDescriptor.m_PeepholeEnabled">LstmDescriptor.m_PeepholeEnabled</a></code>.
m_CellToOutputWeights (ConstTensor): <span><span class="MathJax_Preview">W_{co}</span><script type="math/tex">W_{co}</script></span>, cell-to-output weight matrix. Has effect if <code><a title="pyarmnn.LstmDescriptor.m_PeepholeEnabled" href="#pyarmnn.LstmDescriptor.m_PeepholeEnabled">LstmDescriptor.m_PeepholeEnabled</a></code>.</p>
<p>m_InputGateBias (ConstTensor): <span><span class="MathJax_Preview">b_i</span><script type="math/tex">b_i</script></span>, input gate bias.
m_ForgetGateBias (ConstTensor): <span><span class="MathJax_Preview">b_f</span><script type="math/tex">b_f</script></span>, forget gate bias.
m_CellBias (ConstTensor): <span><span class="MathJax_Preview">b_c</span><script type="math/tex">b_c</script></span>, cell bias.
m_OutputGateBias (ConstTensor): <span><span class="MathJax_Preview">b_o</span><script type="math/tex">b_o</script></span>,
output gate bias.</p>
<p>m_ProjectionWeights (ConstTensor): <span><span class="MathJax_Preview">W_{proj}</span><script type="math/tex">W_{proj}</script></span>, projection weight matrix.
Has effect if <code><a title="pyarmnn.LstmDescriptor.m_ProjectionEnabled" href="#pyarmnn.LstmDescriptor.m_ProjectionEnabled">LstmDescriptor.m_ProjectionEnabled</a></code> is set to True.
m_ProjectionBias (ConstTensor): <span><span class="MathJax_Preview">b_{proj}</span><script type="math/tex">b_{proj}</script></span>, projection bias.
Has effect if <code><a title="pyarmnn.LstmDescriptor.m_ProjectionEnabled" href="#pyarmnn.LstmDescriptor.m_ProjectionEnabled">LstmDescriptor.m_ProjectionEnabled</a></code> is set to True.
m_InputLayerNormWeights (ConstTensor): normalisation weights for input,
has effect if <code><a title="pyarmnn.LstmDescriptor.m_LayerNormEnabled" href="#pyarmnn.LstmDescriptor.m_LayerNormEnabled">LstmDescriptor.m_LayerNormEnabled</a></code> set to True.
m_ForgetLayerNormWeights (ConstTensor): normalisation weights for forget gate,
has effect if <code><a title="pyarmnn.LstmDescriptor.m_LayerNormEnabled" href="#pyarmnn.LstmDescriptor.m_LayerNormEnabled">LstmDescriptor.m_LayerNormEnabled</a></code> set to True.
m_CellLayerNormWeights (ConstTensor): normalisation weights for current cell,
has effect if <code><a title="pyarmnn.LstmDescriptor.m_LayerNormEnabled" href="#pyarmnn.LstmDescriptor.m_LayerNormEnabled">LstmDescriptor.m_LayerNormEnabled</a></code> set to True.
m_OutputLayerNormWeights (ConstTensor): normalisation weights for output gate,
has effect if <code><a title="pyarmnn.LstmDescriptor.m_LayerNormEnabled" href="#pyarmnn.LstmDescriptor.m_LayerNormEnabled">LstmDescriptor.m_LayerNormEnabled</a></code> set to True.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.LstmInputParams.m_CellBias"><code class="name">var <span class="ident">m_CellBias</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_CellLayerNormWeights"><code class="name">var <span class="ident">m_CellLayerNormWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_CellToForgetWeights"><code class="name">var <span class="ident">m_CellToForgetWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_CellToInputWeights"><code class="name">var <span class="ident">m_CellToInputWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_CellToOutputWeights"><code class="name">var <span class="ident">m_CellToOutputWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_ForgetGateBias"><code class="name">var <span class="ident">m_ForgetGateBias</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_ForgetLayerNormWeights"><code class="name">var <span class="ident">m_ForgetLayerNormWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputGateBias"><code class="name">var <span class="ident">m_InputGateBias</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputLayerNormWeights"><code class="name">var <span class="ident">m_InputLayerNormWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputToCellWeights"><code class="name">var <span class="ident">m_InputToCellWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputToForgetWeights"><code class="name">var <span class="ident">m_InputToForgetWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputToInputWeights"><code class="name">var <span class="ident">m_InputToInputWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputToOutputWeights"><code class="name">var <span class="ident">m_InputToOutputWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_OutputGateBias"><code class="name">var <span class="ident">m_OutputGateBias</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_OutputLayerNormWeights"><code class="name">var <span class="ident">m_OutputLayerNormWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_ProjectionBias"><code class="name">var <span class="ident">m_ProjectionBias</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_ProjectionWeights"><code class="name">var <span class="ident">m_ProjectionWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_RecurrentToCellWeights"><code class="name">var <span class="ident">m_RecurrentToCellWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_RecurrentToForgetWeights"><code class="name">var <span class="ident">m_RecurrentToForgetWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_RecurrentToInputWeights"><code class="name">var <span class="ident">m_RecurrentToInputWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.m_RecurrentToOutputWeights"><code class="name">var <span class="ident">m_RecurrentToOutputWeights</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.LstmInputParams.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.MeanDescriptor"><code class="flex name class">
<span>class <span class="ident">MeanDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Mean layer. See <code><a title="pyarmnn.INetwork.AddMeanLayer" href="#pyarmnn.INetwork.AddMeanLayer">INetwork.AddMeanLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_Axis (list of int): Underlying C++ data type is std::vector<unsigned int>. Used to avoid dividing by zero. Values for the dimensions to reduce.
m_KeepDims (bool): Enable/disable keep dimensions. If true, then the reduced dimensions that are of length 1 are kept. Default: False.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.MeanDescriptor.m_Axis"><code class="name">var <span class="ident">m_Axis</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.MeanDescriptor.m_KeepDims"><code class="name">var <span class="ident">m_KeepDims</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.MeanDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.NormalizationDescriptor"><code class="flex name class">
<span>class <span class="ident">NormalizationDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Normalization layer. See <code><a title="pyarmnn.INetwork.AddNormalizationLayer" href="#pyarmnn.INetwork.AddNormalizationLayer">INetwork.AddNormalizationLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_NormChannelType (int): Normalization channel algorithm to use (NormalizationAlgorithmMethod_Across, NormalizationAlgorithmMethod_Within).
Default: NormalizationAlgorithmChannel_Across.
m_NormMethodType (int): Normalization method algorithm to use (NormalizationAlgorithmMethod_LocalBrightness, NormalizationAlgorithmMethod_LocalContrast).
Default: NormalizationAlgorithmMethod_LocalBrightness.
m_NormSize (int): Underlying C++ data type is <code>uint32_t</code>. Depth radius value. Default: 0.
m_Alpha (float): Alpha value for the normalization equation. Default: 0.0.
m_Beta (float): Beta value for the normalization equation. Default: 0.0.
m_K (float): Kappa value used for the across channel normalization equation. Default: 0.0.
m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.NormalizationDescriptor.m_Alpha"><code class="name">var <span class="ident">m_Alpha</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_Beta"><code class="name">var <span class="ident">m_Beta</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_K"><code class="name">var <span class="ident">m_K</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_NormChannelType"><code class="name">var <span class="ident">m_NormChannelType</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_NormMethodType"><code class="name">var <span class="ident">m_NormMethodType</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_NormSize"><code class="name">var <span class="ident">m_NormSize</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.OptimizerOptions"><code class="flex name class">
<span>class <span class="ident">OptimizerOptions</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>Struct for holding options relating to the Arm NN optimizer. See <code><a title="pyarmnn.Optimize" href="#pyarmnn.Optimize">Optimize()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_debug (bool): &hellip;
m_ReduceFp32ToFp16 (bool): &hellip;</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.OptimizerOptions.m_Debug"><code class="name">var <span class="ident">m_Debug</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.OptimizerOptions.m_ReduceFp32ToFp16"><code class="name">var <span class="ident">m_ReduceFp32ToFp16</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.OptimizerOptions.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.PadDescriptor"><code class="flex name class">
<span>class <span class="ident">PadDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Pad layer. See <code><a title="pyarmnn.INetwork.AddPadLayer" href="#pyarmnn.INetwork.AddPadLayer">INetwork.AddPadLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_PadList (list of tuple): specifies the padding for input dimension.
The first tuple value is the number of values to add before the tensor in the dimension.
The second tuple value is the number of values to add after the tensor in the dimension.
The number of pairs should match the number of dimensions in the input tensor.
m_PadValue (bool): Optional value to use for padding. Default: 0.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.PadDescriptor.m_PadList"><code class="name">var <span class="ident">m_PadList</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.PadDescriptor.m_PadValue"><code class="name">var <span class="ident">m_PadValue</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.PadDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.PermutationVector"><code class="flex name class">
<span>class <span class="ident">PermutationVector</span></span>
<span>(</span><span>dimMappings)</span>
</code></dt>
<dd>
<div class="desc"><p>Vector used to permute a tensor.</p>
<p>For a 4-d tensor laid out in a memory with the format (Batch Element, Height, Width, Channels),
which is to be passed as an input to Arm NN, each source dimension is mapped to the corresponding
Arm NN dimension. The Batch dimension remains the same (0 -&gt; 0). The source Height dimension is mapped
to the location of the ArmNN Height dimension (1 -&gt; 2). Similar arguments are made for the Width and
Channels (2 -&gt; 3 and 3 -&gt; 1). This will lead to m_DimMappings pointing to the following array:
[ 0, 2, 3, 1 ].</p>
<p>Note that the mapping should be reversed if considering the case of Arm NN 4-d outputs (Batch Element,
Channels, Height, Width) being written to a destination with the format mentioned above. We now have
0 -&gt; 0, 2 -&gt; 1, 3 -&gt; 2, 1 -&gt; 3, which, when reordered, lead to the following m_DimMappings contents:
[ 0, 3, 1, 2 ].</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dimMappings</code></strong> :&ensp;<code>list</code></dt>
<dd>Indicates how to translate tensor elements from a given source into the target destination,
when source and target potentially have different memory layouts.</dd>
</dl></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.PermutationVector.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.PermutationVector.GetSize"><code class="name flex">
<span>def <span class="ident">GetSize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the PermutationVector size.</p>
<h2 id="return">Return</h2>
<p>SizeType: Current size of the PermutationVector.</p></div>
</dd>
<dt id="pyarmnn.PermutationVector.IsInverse"><code class="name flex">
<span>def <span class="ident">IsInverse</span></span>(<span>self, other)</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if a specified permutation vector is its inverse</p>
<h2 id="return">Return</h2>
<p>bool: returns true if the specified Permutation vector is its inverse.</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.PermuteDescriptor"><code class="flex name class">
<span>class <span class="ident">PermuteDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Permute layer. See <code><a title="pyarmnn.INetwork.AddPermuteLayer" href="#pyarmnn.INetwork.AddPermuteLayer">INetwork.AddPermuteLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_DimMappings (PermutationVector): Indicates how to translate tensor elements from a given source into the target destination,
when source and target potentially have different memory layouts e.g. {0U, 3U, 1U, 2U}.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.PermuteDescriptor.m_DimMappings"><code class="name">var <span class="ident">m_DimMappings</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.PermuteDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor"><code class="flex name class">
<span>class <span class="ident">Pooling2dDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Pooling2d layer. See <code><a title="pyarmnn.INetwork.AddPooling2dLayer" href="#pyarmnn.INetwork.AddPooling2dLayer">INetwork.AddPooling2dLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_PoolType (int): The pooling algorithm to use (<code>PoolingAlgorithm_Max</code>, <code>PoolingAlgorithm_Average</code>, <code>PoolingAlgorithm_L2</code>). Default: <code>PoolingAlgorithm_Max</code>.
m_PadLeft (int): Underlying C++ data type is <code>uint32_t</code>. Padding left value in the width dimension. Default: 0.
m_PadRight (int): Underlying C++ data type is <code>uint32_t</code>. Padding right value in the width dimension. Default: 0.
m_PadTop (int): Underlying C++ data type is <code>uint32_t</code>. Padding top value in the height dimension. Default: 0.
m_PadBottom (int): Underlying C++ data type is <code>uint32_t</code>. Padding bottom value in the height dimension. Default: 0.
m_PoolWidth (int): Underlying C++ data type is <code>uint32_t</code>. Pooling width value. Default: 0.
m_PoolHeight (int): Underlying C++ data type is <code>uint32_t</code>. Pooling height value. Default: 0.
m_StrideX (int): Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the width dimension. Default: 0.
m_StrideY (int): Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the height dimension. Default: 0.
m_OutputShapeRounding (int):
The rounding method for the output shape. (OutputShapeRounding_Floor, OutputShapeRounding_Ceiling).
Default: OutputShapeRounding_Floor.
m_PaddingMethod (int): The padding method to be used. (PaddingMethod_Exclude, PaddingMethod_IgnoreValue).
Default: PaddingMethod_Exclude.
m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.Pooling2dDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_OutputShapeRounding"><code class="name">var <span class="ident">m_OutputShapeRounding</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PadBottom"><code class="name">var <span class="ident">m_PadBottom</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PadLeft"><code class="name">var <span class="ident">m_PadLeft</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PadRight"><code class="name">var <span class="ident">m_PadRight</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PadTop"><code class="name">var <span class="ident">m_PadTop</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PaddingMethod"><code class="name">var <span class="ident">m_PaddingMethod</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PoolHeight"><code class="name">var <span class="ident">m_PoolHeight</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PoolType"><code class="name">var <span class="ident">m_PoolType</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PoolWidth"><code class="name">var <span class="ident">m_PoolWidth</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_StrideX"><code class="name">var <span class="ident">m_StrideX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_StrideY"><code class="name">var <span class="ident">m_StrideY</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ProfilerData"><code class="flex name class">
<span>class <span class="ident">ProfilerData</span></span>
<span>(</span><span>inference_data, per_workload_execution_data)</span>
</code></dt>
<dd>
<div class="desc"><p>Container to hold the profiling inference data, and the profiling data per workload.</p>
<h2 id="contains">Contains</h2>
<p>inference_data (dict): holds end-to-end inference performance data. Keys:
'time_unit' - timer units.
'execution_time' - list of total inference execution times for each inference run.
<br>
per_workload_execution_data (dict): holds per operation performance data, key is a operation name
Each operation has
'time_unit' - timer units. <br>
'execution_time' - list of total execution times for each inference run.
'backend' - backend used for this operation.</p>
<h2 id="example">Example</h2>
<pre><code class="python">&gt;&gt;&gt; data = get_profiling_data(profiler)
&gt;&gt;&gt; print(data)
&gt;&gt;&gt; ProfilerData(inference_data={'time_unit': 'us', 
                                 'execution_time': [8901372.972]}, 
                per_workload_execution_data={'CopyMemGeneric_Execute_#3': {'time_unit': 'us', 
                                                                           'execution_time': [28.941], 
                                                                           'backend': 'Unknown'}, 
                                             'RefConvolution2dWorkload_Execute_#5': {'time_unit': 'us', 
                                                                                     'execution_time': [126838.071], 
                                                                                     'backend': 'CpuRef'}, 
                                             'RefDepthwiseConvolution2dWorkload_Execute_#6': {'time_unit': 'us', 
                                                                                              'execution_time': [49886.208], 
                                                                                              'backend': 'CpuRef'}
                                             ...etc
                                             }
                )
</code></pre></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.tuple</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ProfilerData.inference_data"><code class="name">var <span class="ident">inference_data</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 0</p></div>
</dd>
<dt id="pyarmnn.ProfilerData.per_workload_execution_data"><code class="name">var <span class="ident">per_workload_execution_data</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 1</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ReshapeDescriptor"><code class="flex name class">
<span>class <span class="ident">ReshapeDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Reshape layer. See <code><a title="pyarmnn.INetwork.AddReshapeLayer" href="#pyarmnn.INetwork.AddReshapeLayer">INetwork.AddReshapeLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_TargetShape (TensorShape): Target shape value.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ReshapeDescriptor.m_TargetShape"><code class="name">var <span class="ident">m_TargetShape</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.ReshapeDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ResizeDescriptor"><code class="flex name class">
<span>class <span class="ident">ResizeDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Resize layer. See <code><a title="pyarmnn.INetwork.AddResizeLayer" href="#pyarmnn.INetwork.AddResizeLayer">INetwork.AddResizeLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_TargetWidth (int): Underlying C++ data type is <code>uint32_t</code>. Target width value. Default: 0.
m_TargetHeight (int): Underlying C++ data type is <code>uint32_t</code>. Target height value. Default: 0.
m_Method (int): The Interpolation method to use (ResizeMethod_Bilinear, ResizeMethod_NearestNeighbor).
Default: ResizeMethod_NearestNeighbor.
m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ResizeDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.ResizeDescriptor.m_Method"><code class="name">var <span class="ident">m_Method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.ResizeDescriptor.m_TargetHeight"><code class="name">var <span class="ident">m_TargetHeight</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.ResizeDescriptor.m_TargetWidth"><code class="name">var <span class="ident">m_TargetWidth</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.ResizeDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.SoftmaxDescriptor"><code class="flex name class">
<span>class <span class="ident">SoftmaxDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Softmax layer. See <code><a title="pyarmnn.INetwork.AddSoftmaxLayer" href="#pyarmnn.INetwork.AddSoftmaxLayer">INetwork.AddSoftmaxLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_Beta (float): Exponentiation value.
m_Axis (int): Scalar, defaulted to the last index (-1), specifying the dimension the activation will be performed on.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.SoftmaxDescriptor.m_Axis"><code class="name">var <span class="ident">m_Axis</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.SoftmaxDescriptor.m_Beta"><code class="name">var <span class="ident">m_Beta</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.SoftmaxDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.SpaceToBatchNdDescriptor"><code class="flex name class">
<span>class <span class="ident">SpaceToBatchNdDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Space To Batch N-dimensions layer. See <code><a title="pyarmnn.INetwork.AddSpaceToBatchNdLayer" href="#pyarmnn.INetwork.AddSpaceToBatchNdLayer">INetwork.AddSpaceToBatchNdLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_BlockShape (list of int): Underlying C++ data type is std::vector<unsigned int>. Block shape values. Default: [1, 1].
m_Crops (list of tuple): Specifies the padding values for the input dimension:
[heightPad - (top, bottom) widthPad - (left, right)].
Default: [(0, 0), (0, 0)].
m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.SpaceToBatchNdDescriptor.m_BlockShape"><code class="name">var <span class="ident">m_BlockShape</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.SpaceToBatchNdDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.SpaceToBatchNdDescriptor.m_PadList"><code class="name">var <span class="ident">m_PadList</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.SpaceToBatchNdDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.SpaceToDepthDescriptor"><code class="flex name class">
<span>class <span class="ident">SpaceToDepthDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the SpaceToDepth layer. See <code><a title="pyarmnn.INetwork.AddSpaceToDepthLayer" href="#pyarmnn.INetwork.AddSpaceToDepthLayer">INetwork.AddSpaceToDepthLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_BlockSize (int): Underlying C++ type is <code>unsigned int</code>.
Scalar specifying the input block size. It must be &gt;= 1. Default: 1.
m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NHWC.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.SpaceToDepthDescriptor.m_BlockSize"><code class="name">var <span class="ident">m_BlockSize</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.SpaceToDepthDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.SpaceToDepthDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.SplitterDescriptor"><code class="flex name class">
<span>class <span class="ident">SplitterDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for a Splitter layer. See <code><a title="pyarmnn.INetwork.AddSplitterLayer" href="#pyarmnn.INetwork.AddSplitterLayer">INetwork.AddSplitterLayer()</a></code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>numViews</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of views, the value
must be equal to the number of outputs of a layer.</dd>
<dt><strong><code>numDimensions</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of dimensions. Default value is 4.</dd>
</dl></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.SplitterDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.SplitterDescriptor.GetNumDimensions"><code class="name flex">
<span>def <span class="ident">GetNumDimensions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the number of dimensions.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of dimensions.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.SplitterDescriptor.GetNumViews"><code class="name flex">
<span>def <span class="ident">GetNumViews</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the number of views.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>number of views.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.SplitterDescriptor.GetOrigins"><code class="name flex">
<span>def <span class="ident">GetOrigins</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the view origins that describe how the splitting process is configured.</p>
<p>The number of views is the number of outputs, and their order match.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>OriginsDescriptor</code></dt>
<dd>A descriptor for the origins view.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.SplitterDescriptor.GetViewOrigin"><code class="name flex">
<span>def <span class="ident">GetViewOrigin</span></span>(<span>self, idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the output view origin (shape) by index, the order matches the outputs.</p>
<p>e.g. first view corresponds to the first output, second view to the second output, etc.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>View origin (shape) as a list of ints.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.SplitterDescriptor.GetViewSizes"><code class="name flex">
<span>def <span class="ident">GetViewSizes</span></span>(<span>self, idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the view sizes by index.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>Sizes for the specified index as a list of ints.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.SplitterDescriptor.SetViewOriginCoord"><code class="name flex">
<span>def <span class="ident">SetViewOriginCoord</span></span>(<span>self, view, coord, value)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the value of a specific origin view input coordinate.</p>
<h2 id="contains">Contains</h2>
<p>view (int): Origin view index.
coord (int): Coordinate of the origin view to set.
value (int): Value to set.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If the <code>view</code> is greater than or equal to GetNumViews().
If the <code>coord</code> is greater than or equal to GetNumDimensions().</dd>
</dl></div>
</dd>
<dt id="pyarmnn.SplitterDescriptor.SetViewSize"><code class="name flex">
<span>def <span class="ident">SetViewSize</span></span>(<span>self, view, coord, value)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the size of the views.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>view</code></strong> :&ensp;<code>int</code></dt>
<dd>View index.</dd>
<dt><strong><code>coord</code></strong> :&ensp;<code>int</code></dt>
<dd>Coordinate of the origin view to set.</dd>
<dt><strong><code>value</code></strong> :&ensp;<code>int</code></dt>
<dd>Value to set.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>RuntimeError</code></dt>
<dd>If the <code>view</code> is greater than or equal to GetNumViews().
If the <code>coord</code> is greater than or equal to GetNumDimensions().</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.StackDescriptor"><code class="flex name class">
<span>class <span class="ident">StackDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the Stack layer. See <code><a title="pyarmnn.INetwork.AddStackLayer" href="#pyarmnn.INetwork.AddStackLayer">INetwork.AddStackLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_Axis (int): Underlying C++ type is <code>unsigned int</code>. 0-based axis along which to stack the input tensors. Default: 0.
m_NumInputs (int): Required shape of all input tensors. Default: 0.
m_InputShape (TensorShape): Required shape of all input tensors.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.StackDescriptor.m_Axis"><code class="name">var <span class="ident">m_Axis</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StackDescriptor.m_InputShape"><code class="name">var <span class="ident">m_InputShape</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StackDescriptor.m_NumInputs"><code class="name">var <span class="ident">m_NumInputs</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StackDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor"><code class="flex name class">
<span>class <span class="ident">StridedSliceDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the StridedSlice layer. See <code><a title="pyarmnn.INetwork.AddStridedSliceLayer" href="#pyarmnn.INetwork.AddStridedSliceLayer">INetwork.AddStridedSliceLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_Begin (list of int): Underlying C++ data type is <code>std::vector&lt;int&gt;</code>. Begin values for the input that will be sliced.</p>
<p>m_End (list of int): Underlying C++ data type is <code>std::vector&lt;int&gt;</code>. End values for the input that will be sliced.</p>
<p>m_Stride (list of int): Underlying C++ data type is <code>std::vector&lt;int&gt;</code>. Stride values for the input that will be sliced.</p>
<p>m_BeginMask (int): Underlying C++ data type is <code>int32_t</code>. Begin mask value. If set, then the begin is disregarded and
the fullest range is used for the dimension. Default: 0.</p>
<p>m_EndMask (int): Underlying C++ data type is <code>int32_t</code>. End mask value. If set, then the end is disregarded and
the fullest range is used for the dimension.Default: 0.</p>
<p>m_ShrinkAxisMask (int): Underlying C++ data type is <code>int32_t</code>. Shrink axis mask value. If set, the nth specification shrinks the dimensionality by 1. Default: 0.</p>
<p>m_EllipsisMask (int): Underlying C++ data type is <code>int32_t</code>. Ellipsis mask value. Default: 0.</p>
<p>m_NewAxisMask (int): Underlying C++ data type is <code>int32_t</code>. New axis mask value. If set, the begin, end and stride is disregarded and
a new 1 dimension is inserted to this location of the output tensor. Default: 0.</p>
<p>m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.StridedSliceDescriptor.m_Begin"><code class="name">var <span class="ident">m_Begin</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_BeginMask"><code class="name">var <span class="ident">m_BeginMask</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_EllipsisMask"><code class="name">var <span class="ident">m_EllipsisMask</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_End"><code class="name">var <span class="ident">m_End</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_EndMask"><code class="name">var <span class="ident">m_EndMask</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_NewAxisMask"><code class="name">var <span class="ident">m_NewAxisMask</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_ShrinkAxisMask"><code class="name">var <span class="ident">m_ShrinkAxisMask</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_Stride"><code class="name">var <span class="ident">m_Stride</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.StridedSliceDescriptor.GetStartForAxis"><code class="name flex">
<span>def <span class="ident">GetStartForAxis</span></span>(<span>self, inputShape, axis)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.GetStopForAxis"><code class="name flex">
<span>def <span class="ident">GetStopForAxis</span></span>(<span>self, inputShape, axis, startForAxis)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.Tensor"><code class="flex name class">
<span>class <span class="ident">Tensor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>pyArmnn Tensor object</p>
<p>This class overrides the swig generated Tensor class. The aim of
this is to create an easy to use public api for the Tensor object.</p>
<p>Memory is allocated and managed by this class, avoiding the need to manage
a separate memory area for the tensor compared to the swig generated api.</p>
<p>Create Tensor object.</p>
<p>Supported tensor data types:
DataType_QuantisedAsymm8,
DataType_QuantisedSymm16,
DataType_Signed32,
DataType_Float32,
DataType_Float16</p>
<h2 id="examples">Examples</h2>
<p>Create an empty tensor</p>
<pre><code class="python">&gt;&gt;&gt; import pyarmnn as ann
&gt;&gt;&gt; ann.Tensor()
</code></pre>
<p>Create tensor given tensor information</p>
<pre><code class="python">&gt;&gt;&gt; ann.Tensor(ann.TensorInfo(...))
</code></pre>
<p>Create tensor from another tensor i.e. copy a tensor</p>
<pre><code class="python">&gt;&gt;&gt; ann.Tensor(ann.Tensor())
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt>tensor(Tensor, optional): Create Tensor from a Tensor i.e. copy.</dt>
<dt><strong><code>tensor_info</code></strong> :&ensp;<code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code>, optional</dt>
<dd>Tensor information.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>TypeError</code></dt>
<dd>unsupported input data type.</dd>
<dt><code>ValueError</code></dt>
<dd>appropriate constructor could not be found with provided arguments.</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pyarmnn._generated.pyarmnn.Tensor</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.Tensor.get_memory_area"><code class="name flex">
<span>def <span class="ident">get_memory_area</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get values that are stored by the tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ndarray </code></dt>
<dd>Tensor data (as numpy array).</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.TensorInfo"><code class="flex name class">
<span>class <span class="ident">TensorInfo</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for holding the tensor information of an Arm NN tensor such as quantization, datatype, shape etc.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.TensorInfo.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.TensorInfo.GetDataType"><code class="name flex">
<span>def <span class="ident">GetDataType</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the tensor datatype.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>DataType</code></dt>
<dd>Current tensor DataType.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.GetNumBytes"><code class="name flex">
<span>def <span class="ident">GetNumBytes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the number of bytes needed for this tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of bytes consumed by this tensor.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.GetNumDimensions"><code class="name flex">
<span>def <span class="ident">GetNumDimensions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the number of dimensions in this Tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The number of dimensions in this Tensor.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.GetNumElements"><code class="name flex">
<span>def <span class="ident">GetNumElements</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the total number of elements for this Tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The total number of elements for this Tensor.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.GetQuantizationOffset"><code class="name flex">
<span>def <span class="ident">GetQuantizationOffset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the value of the tensors quantization offset.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Tensor quantization offset value.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.GetQuantizationScale"><code class="name flex">
<span>def <span class="ident">GetQuantizationScale</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the value of the tensors quantization scale.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>Tensor quantization scale value.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.GetShape"><code class="name flex">
<span>def <span class="ident">GetShape</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the tensor shape.</p>
<h2 id="return">Return</h2>
<p>TensorShape: Current shape of the tensor.</p></div>
</dd>
<dt id="pyarmnn.TensorInfo.IsQuantized"><code class="name flex">
<span>def <span class="ident">IsQuantized</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns true if the tensor is a quantized data type.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if the tensor is a quantized data type.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.IsTypeSpaceMatch"><code class="name flex">
<span>def <span class="ident">IsTypeSpaceMatch</span></span>(<span>self, other)</span>
</code></dt>
<dd>
<div class="desc"><p>Check that the types are the same and, if quantize, that the quantization parameters are the same.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if matched, else False.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.SetDataType"><code class="name flex">
<span>def <span class="ident">SetDataType</span></span>(<span>self, type)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the tensor datatype.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>type</code></strong> :&ensp;<code>DataType</code></dt>
<dd>DataType to set the tensor to.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.SetQuantizationOffset"><code class="name flex">
<span>def <span class="ident">SetQuantizationOffset</span></span>(<span>self, offset)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the value of the tensors quantization offset.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>offset</code></strong> :&ensp;<code>int</code></dt>
<dd>Offset value to set.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.SetQuantizationScale"><code class="name flex">
<span>def <span class="ident">SetQuantizationScale</span></span>(<span>self, scale)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the value of the tensors quantization scale.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>scale</code></strong> :&ensp;<code>float</code></dt>
<dd>Scale value to set.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorInfo.SetShape"><code class="name flex">
<span>def <span class="ident">SetShape</span></span>(<span>self, newShape)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the tensor shape. Must have the same number of elements as current tensor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>newShape</code></strong> :&ensp;<code><a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape">TensorShape</a></code></dt>
<dd>New tensor shape to reshape to.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.TensorShape"><code class="flex name class">
<span>class <span class="ident">TensorShape</span></span>
<span>(</span><span>numDimensions)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for holding the shape information of an Arm NN tensor.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.TensorShape.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.TensorShape.GetNumDimensions"><code class="name flex">
<span>def <span class="ident">GetNumDimensions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the number of dimensions in this TensorShape.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The number of dimensions in this TensorShape.</dd>
</dl></div>
</dd>
<dt id="pyarmnn.TensorShape.GetNumElements"><code class="name flex">
<span>def <span class="ident">GetNumElements</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the total number of elements for a tensor with this TensorShape.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The total number of elements for a tensor with this TensorShape.</dd>
</dl></div>
</dd>
</dl>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor"><code class="flex name class">
<span>class <span class="ident">TransposeConvolution2dDescriptor</span></span>
</code></dt>
<dd>
<div class="desc"><p>A descriptor for the TransposeConvolution2d layer. See <code><a title="pyarmnn.INetwork.AddTransposeConvolution2dLayer" href="#pyarmnn.INetwork.AddTransposeConvolution2dLayer">INetwork.AddTransposeConvolution2dLayer()</a></code>.</p>
<h2 id="contains">Contains</h2>
<p>m_PadLeft (int): Underlying C++ data type is <code>uint32_t</code>. Padding left value in the width dimension. Default: 0.
m_PadRight (int): Underlying C++ data type is <code>uint32_t</code>. Padding right value in the width dimension. Default: 0.
m_PadTop (int): Underlying C++ data type is <code>uint32_t</code>. Padding top value in the height dimension. Default: 0.
m_PadBottom (int): Underlying C++ data type is <code>uint32_t</code>. Padding bottom value in the height dimension. Default: 0.
m_StrideX (int): Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the width dimension. Default: 0.
m_StrideY (int): Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the height dimension. Default: 0.
m_BiasEnabled (bool): Enable/disable bias. Default: false.
m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_BiasEnabled"><code class="name">var <span class="ident">m_BiasEnabled</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_PadBottom"><code class="name">var <span class="ident">m_PadBottom</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_PadLeft"><code class="name">var <span class="ident">m_PadLeft</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_PadRight"><code class="name">var <span class="ident">m_PadRight</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_PadTop"><code class="name">var <span class="ident">m_PadTop</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_StrideX"><code class="name">var <span class="ident">m_StrideX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_StrideY"><code class="name">var <span class="ident">m_StrideY</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<div class="desc"><p>The membership flag</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#about-pyarmnn">About PyArmNN</a></li>
<li><a href="#setup-development-environment">Setup development environment</a><ul>
<li><a href="#setup-virtual-environment">Setup virtual environment</a></li>
<li><a href="#build-python-distr">Build python distr</a><ul>
<li><a href="#cmake-build">CMake build</a></li>
<li><a href="#standalone-build">Standalone build</a><ul>
<li><a href="#1-set-environment">1. Set environment:</a></li>
<li><a href="#2-clean-and-build-swig-wrappers">2. Clean and build SWIG wrappers:</a></li>
<li><a href="#4-build-the-source-package">4. Build the source package</a></li>
<li><a href="#5-build-the-binary-package">5. Build the binary package</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#pyarmnn-installation">PyArmNN installation</a><ul>
<li><a href="#installing-from-wheel">Installing from wheel</a></li>
<li><a href="#installing-from-source-package">Installing from source package</a></li>
</ul>
</li>
<li><a href="#pyarmnn-api-overview">PyArmNN API overview</a><ul>
<li><a href="#getting-started">Getting started</a></li>
<li><a href="#examples">Examples</a></li>
<li><a href="#tox-for-automation">Tox for automation</a></li>
<li><a href="#running-unit-tests">Running unit-tests</a></li>
<li><a href="#prebuilt-wheels">Prebuilt wheels</a></li>
</ul>
</li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pyarmnn.CreateDescriptorForConcatenation" href="#pyarmnn.CreateDescriptorForConcatenation">CreateDescriptorForConcatenation</a></code></li>
<li><code><a title="pyarmnn.GetMajorVersion" href="#pyarmnn.GetMajorVersion">GetMajorVersion</a></code></li>
<li><code><a title="pyarmnn.GetMinorVersion" href="#pyarmnn.GetMinorVersion">GetMinorVersion</a></code></li>
<li><code><a title="pyarmnn.GetVersion" href="#pyarmnn.GetVersion">GetVersion</a></code></li>
<li><code><a title="pyarmnn.Optimize" href="#pyarmnn.Optimize">Optimize</a></code></li>
<li><code><a title="pyarmnn.dequantize" href="#pyarmnn.dequantize">dequantize</a></code></li>
<li><code><a title="pyarmnn.get_profiling_data" href="#pyarmnn.get_profiling_data">get_profiling_data</a></code></li>
<li><code><a title="pyarmnn.make_input_tensors" href="#pyarmnn.make_input_tensors">make_input_tensors</a></code></li>
<li><code><a title="pyarmnn.make_output_tensors" href="#pyarmnn.make_output_tensors">make_output_tensors</a></code></li>
<li><code><a title="pyarmnn.quantize" href="#pyarmnn.quantize">quantize</a></code></li>
<li><code><a title="pyarmnn.workload_tensors_to_ndarray" href="#pyarmnn.workload_tensors_to_ndarray">workload_tensors_to_ndarray</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pyarmnn.ActivationDescriptor" href="#pyarmnn.ActivationDescriptor">ActivationDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ActivationDescriptor.m_A" href="#pyarmnn.ActivationDescriptor.m_A">m_A</a></code></li>
<li><code><a title="pyarmnn.ActivationDescriptor.m_B" href="#pyarmnn.ActivationDescriptor.m_B">m_B</a></code></li>
<li><code><a title="pyarmnn.ActivationDescriptor.m_Function" href="#pyarmnn.ActivationDescriptor.m_Function">m_Function</a></code></li>
<li><code><a title="pyarmnn.ActivationDescriptor.thisown" href="#pyarmnn.ActivationDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.BackendId" href="#pyarmnn.BackendId">BackendId</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.BackendId.Get" href="#pyarmnn.BackendId.Get">Get</a></code></li>
<li><code><a title="pyarmnn.BackendId.IsCpuRef" href="#pyarmnn.BackendId.IsCpuRef">IsCpuRef</a></code></li>
<li><code><a title="pyarmnn.BackendId.thisown" href="#pyarmnn.BackendId.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.BatchNormalizationDescriptor" href="#pyarmnn.BatchNormalizationDescriptor">BatchNormalizationDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.BatchNormalizationDescriptor.m_DataLayout" href="#pyarmnn.BatchNormalizationDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.BatchNormalizationDescriptor.m_Eps" href="#pyarmnn.BatchNormalizationDescriptor.m_Eps">m_Eps</a></code></li>
<li><code><a title="pyarmnn.BatchNormalizationDescriptor.thisown" href="#pyarmnn.BatchNormalizationDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.BatchToSpaceNdDescriptor" href="#pyarmnn.BatchToSpaceNdDescriptor">BatchToSpaceNdDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.BatchToSpaceNdDescriptor.m_BlockShape" href="#pyarmnn.BatchToSpaceNdDescriptor.m_BlockShape">m_BlockShape</a></code></li>
<li><code><a title="pyarmnn.BatchToSpaceNdDescriptor.m_Crops" href="#pyarmnn.BatchToSpaceNdDescriptor.m_Crops">m_Crops</a></code></li>
<li><code><a title="pyarmnn.BatchToSpaceNdDescriptor.m_DataLayout" href="#pyarmnn.BatchToSpaceNdDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.BatchToSpaceNdDescriptor.thisown" href="#pyarmnn.BatchToSpaceNdDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ConcatDescriptor" href="#pyarmnn.ConcatDescriptor">ConcatDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.ConcatDescriptor.GetConcatAxis" href="#pyarmnn.ConcatDescriptor.GetConcatAxis">GetConcatAxis</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.GetNumDimensions" href="#pyarmnn.ConcatDescriptor.GetNumDimensions">GetNumDimensions</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.GetNumViews" href="#pyarmnn.ConcatDescriptor.GetNumViews">GetNumViews</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.GetViewOrigin" href="#pyarmnn.ConcatDescriptor.GetViewOrigin">GetViewOrigin</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.SetConcatAxis" href="#pyarmnn.ConcatDescriptor.SetConcatAxis">SetConcatAxis</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.SetViewOriginCoord" href="#pyarmnn.ConcatDescriptor.SetViewOriginCoord">SetViewOriginCoord</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.thisown" href="#pyarmnn.ConcatDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ConstTensor.get_memory_area" href="#pyarmnn.ConstTensor.get_memory_area">get_memory_area</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.Convolution2dDescriptor" href="#pyarmnn.Convolution2dDescriptor">Convolution2dDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_BiasEnabled" href="#pyarmnn.Convolution2dDescriptor.m_BiasEnabled">m_BiasEnabled</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_DataLayout" href="#pyarmnn.Convolution2dDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_DilationX" href="#pyarmnn.Convolution2dDescriptor.m_DilationX">m_DilationX</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_DilationY" href="#pyarmnn.Convolution2dDescriptor.m_DilationY">m_DilationY</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_PadBottom" href="#pyarmnn.Convolution2dDescriptor.m_PadBottom">m_PadBottom</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_PadLeft" href="#pyarmnn.Convolution2dDescriptor.m_PadLeft">m_PadLeft</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_PadRight" href="#pyarmnn.Convolution2dDescriptor.m_PadRight">m_PadRight</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_PadTop" href="#pyarmnn.Convolution2dDescriptor.m_PadTop">m_PadTop</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_StrideX" href="#pyarmnn.Convolution2dDescriptor.m_StrideX">m_StrideX</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_StrideY" href="#pyarmnn.Convolution2dDescriptor.m_StrideY">m_StrideY</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.thisown" href="#pyarmnn.Convolution2dDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.CreationOptions" href="#pyarmnn.CreationOptions">CreationOptions</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.CreationOptions.m_DynamicBackendsPath" href="#pyarmnn.CreationOptions.m_DynamicBackendsPath">m_DynamicBackendsPath</a></code></li>
<li><code><a title="pyarmnn.CreationOptions.m_EnableGpuProfiling" href="#pyarmnn.CreationOptions.m_EnableGpuProfiling">m_EnableGpuProfiling</a></code></li>
<li><code><a title="pyarmnn.CreationOptions.m_GpuAccTunedParameters" href="#pyarmnn.CreationOptions.m_GpuAccTunedParameters">m_GpuAccTunedParameters</a></code></li>
<li><code><a title="pyarmnn.CreationOptions.thisown" href="#pyarmnn.CreationOptions.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor" href="#pyarmnn.DepthwiseConvolution2dDescriptor">DepthwiseConvolution2dDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_BiasEnabled" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_BiasEnabled">m_BiasEnabled</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_DataLayout" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationX" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationX">m_DilationX</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationY" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationY">m_DilationY</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadBottom" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_PadBottom">m_PadBottom</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadLeft" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_PadLeft">m_PadLeft</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadRight" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_PadRight">m_PadRight</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadTop" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_PadTop">m_PadTop</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideX" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideX">m_StrideX</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideY" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideY">m_StrideY</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.thisown" href="#pyarmnn.DepthwiseConvolution2dDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.DetectionPostProcessDescriptor" href="#pyarmnn.DetectionPostProcessDescriptor">DetectionPostProcessDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_DetectionsPerClass" href="#pyarmnn.DetectionPostProcessDescriptor.m_DetectionsPerClass">m_DetectionsPerClass</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_MaxClassesPerDetection" href="#pyarmnn.DetectionPostProcessDescriptor.m_MaxClassesPerDetection">m_MaxClassesPerDetection</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_MaxDetections" href="#pyarmnn.DetectionPostProcessDescriptor.m_MaxDetections">m_MaxDetections</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_NmsIouThreshold" href="#pyarmnn.DetectionPostProcessDescriptor.m_NmsIouThreshold">m_NmsIouThreshold</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_NmsScoreThreshold" href="#pyarmnn.DetectionPostProcessDescriptor.m_NmsScoreThreshold">m_NmsScoreThreshold</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_NumClasses" href="#pyarmnn.DetectionPostProcessDescriptor.m_NumClasses">m_NumClasses</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_ScaleH" href="#pyarmnn.DetectionPostProcessDescriptor.m_ScaleH">m_ScaleH</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_ScaleW" href="#pyarmnn.DetectionPostProcessDescriptor.m_ScaleW">m_ScaleW</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_ScaleX" href="#pyarmnn.DetectionPostProcessDescriptor.m_ScaleX">m_ScaleX</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_ScaleY" href="#pyarmnn.DetectionPostProcessDescriptor.m_ScaleY">m_ScaleY</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_UseRegularNms" href="#pyarmnn.DetectionPostProcessDescriptor.m_UseRegularNms">m_UseRegularNms</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.thisown" href="#pyarmnn.DetectionPostProcessDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.FakeQuantizationDescriptor" href="#pyarmnn.FakeQuantizationDescriptor">FakeQuantizationDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.FakeQuantizationDescriptor.m_Max" href="#pyarmnn.FakeQuantizationDescriptor.m_Max">m_Max</a></code></li>
<li><code><a title="pyarmnn.FakeQuantizationDescriptor.m_Min" href="#pyarmnn.FakeQuantizationDescriptor.m_Min">m_Min</a></code></li>
<li><code><a title="pyarmnn.FakeQuantizationDescriptor.thisown" href="#pyarmnn.FakeQuantizationDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.FullyConnectedDescriptor" href="#pyarmnn.FullyConnectedDescriptor">FullyConnectedDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.FullyConnectedDescriptor.m_BiasEnabled" href="#pyarmnn.FullyConnectedDescriptor.m_BiasEnabled">m_BiasEnabled</a></code></li>
<li><code><a title="pyarmnn.FullyConnectedDescriptor.m_TransposeWeightMatrix" href="#pyarmnn.FullyConnectedDescriptor.m_TransposeWeightMatrix">m_TransposeWeightMatrix</a></code></li>
<li><code><a title="pyarmnn.FullyConnectedDescriptor.thisown" href="#pyarmnn.FullyConnectedDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ICaffeParser" href="#pyarmnn.ICaffeParser">ICaffeParser</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ICaffeParser.CreateNetworkFromBinaryFile" href="#pyarmnn.ICaffeParser.CreateNetworkFromBinaryFile">CreateNetworkFromBinaryFile</a></code></li>
<li><code><a title="pyarmnn.ICaffeParser.GetNetworkInputBindingInfo" href="#pyarmnn.ICaffeParser.GetNetworkInputBindingInfo">GetNetworkInputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ICaffeParser.GetNetworkOutputBindingInfo" href="#pyarmnn.ICaffeParser.GetNetworkOutputBindingInfo">GetNetworkOutputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ICaffeParser.thisown" href="#pyarmnn.ICaffeParser.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.IConnectableLayer.GetGuid" href="#pyarmnn.IConnectableLayer.GetGuid">GetGuid</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.GetInputSlot" href="#pyarmnn.IConnectableLayer.GetInputSlot">GetInputSlot</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.GetName" href="#pyarmnn.IConnectableLayer.GetName">GetName</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.GetNumInputSlots" href="#pyarmnn.IConnectableLayer.GetNumInputSlots">GetNumInputSlots</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.GetNumOutputSlots" href="#pyarmnn.IConnectableLayer.GetNumOutputSlots">GetNumOutputSlots</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.GetOutputSlot" href="#pyarmnn.IConnectableLayer.GetOutputSlot">GetOutputSlot</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.thisown" href="#pyarmnn.IConnectableLayer.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IDeviceSpec" href="#pyarmnn.IDeviceSpec">IDeviceSpec</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IDeviceSpec.GetSupportedBackends" href="#pyarmnn.IDeviceSpec.GetSupportedBackends">GetSupportedBackends</a></code></li>
<li><code><a title="pyarmnn.IDeviceSpec.thisown" href="#pyarmnn.IDeviceSpec.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot">IInputSlot</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IInputSlot.GetConnection" href="#pyarmnn.IInputSlot.GetConnection">GetConnection</a></code></li>
<li><code><a title="pyarmnn.IInputSlot.thisown" href="#pyarmnn.IInputSlot.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork">INetwork</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.INetwork.AddActivationLayer" href="#pyarmnn.INetwork.AddActivationLayer">AddActivationLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddAdditionLayer" href="#pyarmnn.INetwork.AddAdditionLayer">AddAdditionLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddBatchNormalizationLayer" href="#pyarmnn.INetwork.AddBatchNormalizationLayer">AddBatchNormalizationLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddBatchToSpaceNdLayer" href="#pyarmnn.INetwork.AddBatchToSpaceNdLayer">AddBatchToSpaceNdLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddConcatLayer" href="#pyarmnn.INetwork.AddConcatLayer">AddConcatLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddConstantLayer" href="#pyarmnn.INetwork.AddConstantLayer">AddConstantLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddConvolution2dLayer" href="#pyarmnn.INetwork.AddConvolution2dLayer">AddConvolution2dLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddDepthwiseConvolution2dLayer" href="#pyarmnn.INetwork.AddDepthwiseConvolution2dLayer">AddDepthwiseConvolution2dLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddDequantizeLayer" href="#pyarmnn.INetwork.AddDequantizeLayer">AddDequantizeLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddDetectionPostProcessLayer" href="#pyarmnn.INetwork.AddDetectionPostProcessLayer">AddDetectionPostProcessLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddDivisionLayer" href="#pyarmnn.INetwork.AddDivisionLayer">AddDivisionLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddFloorLayer" href="#pyarmnn.INetwork.AddFloorLayer">AddFloorLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddFullyConnectedLayer" href="#pyarmnn.INetwork.AddFullyConnectedLayer">AddFullyConnectedLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddGatherLayer" href="#pyarmnn.INetwork.AddGatherLayer">AddGatherLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddInputLayer" href="#pyarmnn.INetwork.AddInputLayer">AddInputLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddL2NormalizationLayer" href="#pyarmnn.INetwork.AddL2NormalizationLayer">AddL2NormalizationLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddLstmLayer" href="#pyarmnn.INetwork.AddLstmLayer">AddLstmLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddMaximumLayer" href="#pyarmnn.INetwork.AddMaximumLayer">AddMaximumLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddMeanLayer" href="#pyarmnn.INetwork.AddMeanLayer">AddMeanLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddMergeLayer" href="#pyarmnn.INetwork.AddMergeLayer">AddMergeLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddMinimumLayer" href="#pyarmnn.INetwork.AddMinimumLayer">AddMinimumLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddMultiplicationLayer" href="#pyarmnn.INetwork.AddMultiplicationLayer">AddMultiplicationLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddNormalizationLayer" href="#pyarmnn.INetwork.AddNormalizationLayer">AddNormalizationLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddOutputLayer" href="#pyarmnn.INetwork.AddOutputLayer">AddOutputLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddPadLayer" href="#pyarmnn.INetwork.AddPadLayer">AddPadLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddPermuteLayer" href="#pyarmnn.INetwork.AddPermuteLayer">AddPermuteLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddPooling2dLayer" href="#pyarmnn.INetwork.AddPooling2dLayer">AddPooling2dLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddPreluLayer" href="#pyarmnn.INetwork.AddPreluLayer">AddPreluLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddQuantizeLayer" href="#pyarmnn.INetwork.AddQuantizeLayer">AddQuantizeLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddQuantizedLstmLayer" href="#pyarmnn.INetwork.AddQuantizedLstmLayer">AddQuantizedLstmLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddReshapeLayer" href="#pyarmnn.INetwork.AddReshapeLayer">AddReshapeLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddResizeLayer" href="#pyarmnn.INetwork.AddResizeLayer">AddResizeLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddRsqrtLayer" href="#pyarmnn.INetwork.AddRsqrtLayer">AddRsqrtLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSoftmaxLayer" href="#pyarmnn.INetwork.AddSoftmaxLayer">AddSoftmaxLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSpaceToBatchNdLayer" href="#pyarmnn.INetwork.AddSpaceToBatchNdLayer">AddSpaceToBatchNdLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSpaceToDepthLayer" href="#pyarmnn.INetwork.AddSpaceToDepthLayer">AddSpaceToDepthLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSplitterLayer" href="#pyarmnn.INetwork.AddSplitterLayer">AddSplitterLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddStackLayer" href="#pyarmnn.INetwork.AddStackLayer">AddStackLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddStridedSliceLayer" href="#pyarmnn.INetwork.AddStridedSliceLayer">AddStridedSliceLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSubtractionLayer" href="#pyarmnn.INetwork.AddSubtractionLayer">AddSubtractionLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSwitchLayer" href="#pyarmnn.INetwork.AddSwitchLayer">AddSwitchLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddTransposeConvolution2dLayer" href="#pyarmnn.INetwork.AddTransposeConvolution2dLayer">AddTransposeConvolution2dLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.thisown" href="#pyarmnn.INetwork.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IOnnxParser" href="#pyarmnn.IOnnxParser">IOnnxParser</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IOnnxParser.CreateNetworkFromBinaryFile" href="#pyarmnn.IOnnxParser.CreateNetworkFromBinaryFile">CreateNetworkFromBinaryFile</a></code></li>
<li><code><a title="pyarmnn.IOnnxParser.GetNetworkInputBindingInfo" href="#pyarmnn.IOnnxParser.GetNetworkInputBindingInfo">GetNetworkInputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.IOnnxParser.GetNetworkOutputBindingInfo" href="#pyarmnn.IOnnxParser.GetNetworkOutputBindingInfo">GetNetworkOutputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.IOnnxParser.thisown" href="#pyarmnn.IOnnxParser.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IOptimizedNetwork" href="#pyarmnn.IOptimizedNetwork">IOptimizedNetwork</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IOptimizedNetwork.SerializeToDot" href="#pyarmnn.IOptimizedNetwork.SerializeToDot">SerializeToDot</a></code></li>
<li><code><a title="pyarmnn.IOptimizedNetwork.thisown" href="#pyarmnn.IOptimizedNetwork.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IOutputSlot" href="#pyarmnn.IOutputSlot">IOutputSlot</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IOutputSlot.CalculateIndexOnOwner" href="#pyarmnn.IOutputSlot.CalculateIndexOnOwner">CalculateIndexOnOwner</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.Connect" href="#pyarmnn.IOutputSlot.Connect">Connect</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.Disconnect" href="#pyarmnn.IOutputSlot.Disconnect">Disconnect</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.GetConnection" href="#pyarmnn.IOutputSlot.GetConnection">GetConnection</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.GetNumConnections" href="#pyarmnn.IOutputSlot.GetNumConnections">GetNumConnections</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.GetOwningLayerGuid" href="#pyarmnn.IOutputSlot.GetOwningLayerGuid">GetOwningLayerGuid</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.GetTensorInfo" href="#pyarmnn.IOutputSlot.GetTensorInfo">GetTensorInfo</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.IsTensorInfoSet" href="#pyarmnn.IOutputSlot.IsTensorInfoSet">IsTensorInfoSet</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.SetTensorInfo" href="#pyarmnn.IOutputSlot.SetTensorInfo">SetTensorInfo</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.thisown" href="#pyarmnn.IOutputSlot.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IProfiler" href="#pyarmnn.IProfiler">IProfiler</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IProfiler.EnableProfiling" href="#pyarmnn.IProfiler.EnableProfiling">EnableProfiling</a></code></li>
<li><code><a title="pyarmnn.IProfiler.IsProfilingEnabled" href="#pyarmnn.IProfiler.IsProfilingEnabled">IsProfilingEnabled</a></code></li>
<li><code><a title="pyarmnn.IProfiler.as_json" href="#pyarmnn.IProfiler.as_json">as_json</a></code></li>
<li><code><a title="pyarmnn.IProfiler.event_log" href="#pyarmnn.IProfiler.event_log">event_log</a></code></li>
<li><code><a title="pyarmnn.IProfiler.thisown" href="#pyarmnn.IProfiler.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IRuntime" href="#pyarmnn.IRuntime">IRuntime</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">EnqueueWorkload</a></code></li>
<li><code><a title="pyarmnn.IRuntime.GetDeviceSpec" href="#pyarmnn.IRuntime.GetDeviceSpec">GetDeviceSpec</a></code></li>
<li><code><a title="pyarmnn.IRuntime.GetInputTensorInfo" href="#pyarmnn.IRuntime.GetInputTensorInfo">GetInputTensorInfo</a></code></li>
<li><code><a title="pyarmnn.IRuntime.GetOutputTensorInfo" href="#pyarmnn.IRuntime.GetOutputTensorInfo">GetOutputTensorInfo</a></code></li>
<li><code><a title="pyarmnn.IRuntime.GetProfiler" href="#pyarmnn.IRuntime.GetProfiler">GetProfiler</a></code></li>
<li><code><a title="pyarmnn.IRuntime.LoadNetwork" href="#pyarmnn.IRuntime.LoadNetwork">LoadNetwork</a></code></li>
<li><code><a title="pyarmnn.IRuntime.UnloadNetwork" href="#pyarmnn.IRuntime.UnloadNetwork">UnloadNetwork</a></code></li>
<li><code><a title="pyarmnn.IRuntime.thisown" href="#pyarmnn.IRuntime.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ITfLiteParser" href="#pyarmnn.ITfLiteParser">ITfLiteParser</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ITfLiteParser.CreateNetworkFromBinaryFile" href="#pyarmnn.ITfLiteParser.CreateNetworkFromBinaryFile">CreateNetworkFromBinaryFile</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.GetNetworkInputBindingInfo" href="#pyarmnn.ITfLiteParser.GetNetworkInputBindingInfo">GetNetworkInputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.GetNetworkOutputBindingInfo" href="#pyarmnn.ITfLiteParser.GetNetworkOutputBindingInfo">GetNetworkOutputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.GetSubgraphCount" href="#pyarmnn.ITfLiteParser.GetSubgraphCount">GetSubgraphCount</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.GetSubgraphInputTensorNames" href="#pyarmnn.ITfLiteParser.GetSubgraphInputTensorNames">GetSubgraphInputTensorNames</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.GetSubgraphOutputTensorNames" href="#pyarmnn.ITfLiteParser.GetSubgraphOutputTensorNames">GetSubgraphOutputTensorNames</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.thisown" href="#pyarmnn.ITfLiteParser.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ITfParser" href="#pyarmnn.ITfParser">ITfParser</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ITfParser.CreateNetworkFromBinaryFile" href="#pyarmnn.ITfParser.CreateNetworkFromBinaryFile">CreateNetworkFromBinaryFile</a></code></li>
<li><code><a title="pyarmnn.ITfParser.GetNetworkInputBindingInfo" href="#pyarmnn.ITfParser.GetNetworkInputBindingInfo">GetNetworkInputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ITfParser.GetNetworkOutputBindingInfo" href="#pyarmnn.ITfParser.GetNetworkOutputBindingInfo">GetNetworkOutputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ITfParser.thisown" href="#pyarmnn.ITfParser.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.L2NormalizationDescriptor" href="#pyarmnn.L2NormalizationDescriptor">L2NormalizationDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.L2NormalizationDescriptor.m_DataLayout" href="#pyarmnn.L2NormalizationDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.L2NormalizationDescriptor.m_Eps" href="#pyarmnn.L2NormalizationDescriptor.m_Eps">m_Eps</a></code></li>
<li><code><a title="pyarmnn.L2NormalizationDescriptor.thisown" href="#pyarmnn.L2NormalizationDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.LstmDescriptor" href="#pyarmnn.LstmDescriptor">LstmDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.LstmDescriptor.m_ActivationFunc" href="#pyarmnn.LstmDescriptor.m_ActivationFunc">m_ActivationFunc</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_CifgEnabled" href="#pyarmnn.LstmDescriptor.m_CifgEnabled">m_CifgEnabled</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_ClippingThresCell" href="#pyarmnn.LstmDescriptor.m_ClippingThresCell">m_ClippingThresCell</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_ClippingThresProj" href="#pyarmnn.LstmDescriptor.m_ClippingThresProj">m_ClippingThresProj</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_LayerNormEnabled" href="#pyarmnn.LstmDescriptor.m_LayerNormEnabled">m_LayerNormEnabled</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_PeepholeEnabled" href="#pyarmnn.LstmDescriptor.m_PeepholeEnabled">m_PeepholeEnabled</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_ProjectionEnabled" href="#pyarmnn.LstmDescriptor.m_ProjectionEnabled">m_ProjectionEnabled</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.thisown" href="#pyarmnn.LstmDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.LstmInputParams" href="#pyarmnn.LstmInputParams">LstmInputParams</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.LstmInputParams.m_CellBias" href="#pyarmnn.LstmInputParams.m_CellBias">m_CellBias</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_CellLayerNormWeights" href="#pyarmnn.LstmInputParams.m_CellLayerNormWeights">m_CellLayerNormWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_CellToForgetWeights" href="#pyarmnn.LstmInputParams.m_CellToForgetWeights">m_CellToForgetWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_CellToInputWeights" href="#pyarmnn.LstmInputParams.m_CellToInputWeights">m_CellToInputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_CellToOutputWeights" href="#pyarmnn.LstmInputParams.m_CellToOutputWeights">m_CellToOutputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_ForgetGateBias" href="#pyarmnn.LstmInputParams.m_ForgetGateBias">m_ForgetGateBias</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_ForgetLayerNormWeights" href="#pyarmnn.LstmInputParams.m_ForgetLayerNormWeights">m_ForgetLayerNormWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputGateBias" href="#pyarmnn.LstmInputParams.m_InputGateBias">m_InputGateBias</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputLayerNormWeights" href="#pyarmnn.LstmInputParams.m_InputLayerNormWeights">m_InputLayerNormWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputToCellWeights" href="#pyarmnn.LstmInputParams.m_InputToCellWeights">m_InputToCellWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputToForgetWeights" href="#pyarmnn.LstmInputParams.m_InputToForgetWeights">m_InputToForgetWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputToInputWeights" href="#pyarmnn.LstmInputParams.m_InputToInputWeights">m_InputToInputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputToOutputWeights" href="#pyarmnn.LstmInputParams.m_InputToOutputWeights">m_InputToOutputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_OutputGateBias" href="#pyarmnn.LstmInputParams.m_OutputGateBias">m_OutputGateBias</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_OutputLayerNormWeights" href="#pyarmnn.LstmInputParams.m_OutputLayerNormWeights">m_OutputLayerNormWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_ProjectionBias" href="#pyarmnn.LstmInputParams.m_ProjectionBias">m_ProjectionBias</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_ProjectionWeights" href="#pyarmnn.LstmInputParams.m_ProjectionWeights">m_ProjectionWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_RecurrentToCellWeights" href="#pyarmnn.LstmInputParams.m_RecurrentToCellWeights">m_RecurrentToCellWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_RecurrentToForgetWeights" href="#pyarmnn.LstmInputParams.m_RecurrentToForgetWeights">m_RecurrentToForgetWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_RecurrentToInputWeights" href="#pyarmnn.LstmInputParams.m_RecurrentToInputWeights">m_RecurrentToInputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_RecurrentToOutputWeights" href="#pyarmnn.LstmInputParams.m_RecurrentToOutputWeights">m_RecurrentToOutputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.thisown" href="#pyarmnn.LstmInputParams.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.MeanDescriptor" href="#pyarmnn.MeanDescriptor">MeanDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.MeanDescriptor.m_Axis" href="#pyarmnn.MeanDescriptor.m_Axis">m_Axis</a></code></li>
<li><code><a title="pyarmnn.MeanDescriptor.m_KeepDims" href="#pyarmnn.MeanDescriptor.m_KeepDims">m_KeepDims</a></code></li>
<li><code><a title="pyarmnn.MeanDescriptor.thisown" href="#pyarmnn.MeanDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.NormalizationDescriptor" href="#pyarmnn.NormalizationDescriptor">NormalizationDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.NormalizationDescriptor.m_Alpha" href="#pyarmnn.NormalizationDescriptor.m_Alpha">m_Alpha</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_Beta" href="#pyarmnn.NormalizationDescriptor.m_Beta">m_Beta</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_DataLayout" href="#pyarmnn.NormalizationDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_K" href="#pyarmnn.NormalizationDescriptor.m_K">m_K</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_NormChannelType" href="#pyarmnn.NormalizationDescriptor.m_NormChannelType">m_NormChannelType</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_NormMethodType" href="#pyarmnn.NormalizationDescriptor.m_NormMethodType">m_NormMethodType</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_NormSize" href="#pyarmnn.NormalizationDescriptor.m_NormSize">m_NormSize</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.thisown" href="#pyarmnn.NormalizationDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.OptimizerOptions" href="#pyarmnn.OptimizerOptions">OptimizerOptions</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.OptimizerOptions.m_Debug" href="#pyarmnn.OptimizerOptions.m_Debug">m_Debug</a></code></li>
<li><code><a title="pyarmnn.OptimizerOptions.m_ReduceFp32ToFp16" href="#pyarmnn.OptimizerOptions.m_ReduceFp32ToFp16">m_ReduceFp32ToFp16</a></code></li>
<li><code><a title="pyarmnn.OptimizerOptions.thisown" href="#pyarmnn.OptimizerOptions.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.PadDescriptor" href="#pyarmnn.PadDescriptor">PadDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.PadDescriptor.m_PadList" href="#pyarmnn.PadDescriptor.m_PadList">m_PadList</a></code></li>
<li><code><a title="pyarmnn.PadDescriptor.m_PadValue" href="#pyarmnn.PadDescriptor.m_PadValue">m_PadValue</a></code></li>
<li><code><a title="pyarmnn.PadDescriptor.thisown" href="#pyarmnn.PadDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.PermutationVector" href="#pyarmnn.PermutationVector">PermutationVector</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.PermutationVector.GetSize" href="#pyarmnn.PermutationVector.GetSize">GetSize</a></code></li>
<li><code><a title="pyarmnn.PermutationVector.IsInverse" href="#pyarmnn.PermutationVector.IsInverse">IsInverse</a></code></li>
<li><code><a title="pyarmnn.PermutationVector.thisown" href="#pyarmnn.PermutationVector.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.PermuteDescriptor" href="#pyarmnn.PermuteDescriptor">PermuteDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.PermuteDescriptor.m_DimMappings" href="#pyarmnn.PermuteDescriptor.m_DimMappings">m_DimMappings</a></code></li>
<li><code><a title="pyarmnn.PermuteDescriptor.thisown" href="#pyarmnn.PermuteDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.Pooling2dDescriptor" href="#pyarmnn.Pooling2dDescriptor">Pooling2dDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_DataLayout" href="#pyarmnn.Pooling2dDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_OutputShapeRounding" href="#pyarmnn.Pooling2dDescriptor.m_OutputShapeRounding">m_OutputShapeRounding</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PadBottom" href="#pyarmnn.Pooling2dDescriptor.m_PadBottom">m_PadBottom</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PadLeft" href="#pyarmnn.Pooling2dDescriptor.m_PadLeft">m_PadLeft</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PadRight" href="#pyarmnn.Pooling2dDescriptor.m_PadRight">m_PadRight</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PadTop" href="#pyarmnn.Pooling2dDescriptor.m_PadTop">m_PadTop</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PaddingMethod" href="#pyarmnn.Pooling2dDescriptor.m_PaddingMethod">m_PaddingMethod</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PoolHeight" href="#pyarmnn.Pooling2dDescriptor.m_PoolHeight">m_PoolHeight</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PoolType" href="#pyarmnn.Pooling2dDescriptor.m_PoolType">m_PoolType</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PoolWidth" href="#pyarmnn.Pooling2dDescriptor.m_PoolWidth">m_PoolWidth</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_StrideX" href="#pyarmnn.Pooling2dDescriptor.m_StrideX">m_StrideX</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_StrideY" href="#pyarmnn.Pooling2dDescriptor.m_StrideY">m_StrideY</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.thisown" href="#pyarmnn.Pooling2dDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ProfilerData" href="#pyarmnn.ProfilerData">ProfilerData</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ProfilerData.inference_data" href="#pyarmnn.ProfilerData.inference_data">inference_data</a></code></li>
<li><code><a title="pyarmnn.ProfilerData.per_workload_execution_data" href="#pyarmnn.ProfilerData.per_workload_execution_data">per_workload_execution_data</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ReshapeDescriptor" href="#pyarmnn.ReshapeDescriptor">ReshapeDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ReshapeDescriptor.m_TargetShape" href="#pyarmnn.ReshapeDescriptor.m_TargetShape">m_TargetShape</a></code></li>
<li><code><a title="pyarmnn.ReshapeDescriptor.thisown" href="#pyarmnn.ReshapeDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ResizeDescriptor" href="#pyarmnn.ResizeDescriptor">ResizeDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ResizeDescriptor.m_DataLayout" href="#pyarmnn.ResizeDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.ResizeDescriptor.m_Method" href="#pyarmnn.ResizeDescriptor.m_Method">m_Method</a></code></li>
<li><code><a title="pyarmnn.ResizeDescriptor.m_TargetHeight" href="#pyarmnn.ResizeDescriptor.m_TargetHeight">m_TargetHeight</a></code></li>
<li><code><a title="pyarmnn.ResizeDescriptor.m_TargetWidth" href="#pyarmnn.ResizeDescriptor.m_TargetWidth">m_TargetWidth</a></code></li>
<li><code><a title="pyarmnn.ResizeDescriptor.thisown" href="#pyarmnn.ResizeDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.SoftmaxDescriptor" href="#pyarmnn.SoftmaxDescriptor">SoftmaxDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.SoftmaxDescriptor.m_Axis" href="#pyarmnn.SoftmaxDescriptor.m_Axis">m_Axis</a></code></li>
<li><code><a title="pyarmnn.SoftmaxDescriptor.m_Beta" href="#pyarmnn.SoftmaxDescriptor.m_Beta">m_Beta</a></code></li>
<li><code><a title="pyarmnn.SoftmaxDescriptor.thisown" href="#pyarmnn.SoftmaxDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.SpaceToBatchNdDescriptor" href="#pyarmnn.SpaceToBatchNdDescriptor">SpaceToBatchNdDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.SpaceToBatchNdDescriptor.m_BlockShape" href="#pyarmnn.SpaceToBatchNdDescriptor.m_BlockShape">m_BlockShape</a></code></li>
<li><code><a title="pyarmnn.SpaceToBatchNdDescriptor.m_DataLayout" href="#pyarmnn.SpaceToBatchNdDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.SpaceToBatchNdDescriptor.m_PadList" href="#pyarmnn.SpaceToBatchNdDescriptor.m_PadList">m_PadList</a></code></li>
<li><code><a title="pyarmnn.SpaceToBatchNdDescriptor.thisown" href="#pyarmnn.SpaceToBatchNdDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.SpaceToDepthDescriptor" href="#pyarmnn.SpaceToDepthDescriptor">SpaceToDepthDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.SpaceToDepthDescriptor.m_BlockSize" href="#pyarmnn.SpaceToDepthDescriptor.m_BlockSize">m_BlockSize</a></code></li>
<li><code><a title="pyarmnn.SpaceToDepthDescriptor.m_DataLayout" href="#pyarmnn.SpaceToDepthDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.SpaceToDepthDescriptor.thisown" href="#pyarmnn.SpaceToDepthDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.SplitterDescriptor" href="#pyarmnn.SplitterDescriptor">SplitterDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.SplitterDescriptor.GetNumDimensions" href="#pyarmnn.SplitterDescriptor.GetNumDimensions">GetNumDimensions</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.GetNumViews" href="#pyarmnn.SplitterDescriptor.GetNumViews">GetNumViews</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.GetOrigins" href="#pyarmnn.SplitterDescriptor.GetOrigins">GetOrigins</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.GetViewOrigin" href="#pyarmnn.SplitterDescriptor.GetViewOrigin">GetViewOrigin</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.GetViewSizes" href="#pyarmnn.SplitterDescriptor.GetViewSizes">GetViewSizes</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.SetViewOriginCoord" href="#pyarmnn.SplitterDescriptor.SetViewOriginCoord">SetViewOriginCoord</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.SetViewSize" href="#pyarmnn.SplitterDescriptor.SetViewSize">SetViewSize</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.thisown" href="#pyarmnn.SplitterDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.StackDescriptor" href="#pyarmnn.StackDescriptor">StackDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.StackDescriptor.m_Axis" href="#pyarmnn.StackDescriptor.m_Axis">m_Axis</a></code></li>
<li><code><a title="pyarmnn.StackDescriptor.m_InputShape" href="#pyarmnn.StackDescriptor.m_InputShape">m_InputShape</a></code></li>
<li><code><a title="pyarmnn.StackDescriptor.m_NumInputs" href="#pyarmnn.StackDescriptor.m_NumInputs">m_NumInputs</a></code></li>
<li><code><a title="pyarmnn.StackDescriptor.thisown" href="#pyarmnn.StackDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.StridedSliceDescriptor" href="#pyarmnn.StridedSliceDescriptor">StridedSliceDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.StridedSliceDescriptor.GetStartForAxis" href="#pyarmnn.StridedSliceDescriptor.GetStartForAxis">GetStartForAxis</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.GetStopForAxis" href="#pyarmnn.StridedSliceDescriptor.GetStopForAxis">GetStopForAxis</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_Begin" href="#pyarmnn.StridedSliceDescriptor.m_Begin">m_Begin</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_BeginMask" href="#pyarmnn.StridedSliceDescriptor.m_BeginMask">m_BeginMask</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_DataLayout" href="#pyarmnn.StridedSliceDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_EllipsisMask" href="#pyarmnn.StridedSliceDescriptor.m_EllipsisMask">m_EllipsisMask</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_End" href="#pyarmnn.StridedSliceDescriptor.m_End">m_End</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_EndMask" href="#pyarmnn.StridedSliceDescriptor.m_EndMask">m_EndMask</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_NewAxisMask" href="#pyarmnn.StridedSliceDescriptor.m_NewAxisMask">m_NewAxisMask</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_ShrinkAxisMask" href="#pyarmnn.StridedSliceDescriptor.m_ShrinkAxisMask">m_ShrinkAxisMask</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_Stride" href="#pyarmnn.StridedSliceDescriptor.m_Stride">m_Stride</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.thisown" href="#pyarmnn.StridedSliceDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.Tensor" href="#pyarmnn.Tensor">Tensor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.Tensor.get_memory_area" href="#pyarmnn.Tensor.get_memory_area">get_memory_area</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.TensorInfo.GetDataType" href="#pyarmnn.TensorInfo.GetDataType">GetDataType</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetNumBytes" href="#pyarmnn.TensorInfo.GetNumBytes">GetNumBytes</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetNumDimensions" href="#pyarmnn.TensorInfo.GetNumDimensions">GetNumDimensions</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetNumElements" href="#pyarmnn.TensorInfo.GetNumElements">GetNumElements</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetQuantizationOffset" href="#pyarmnn.TensorInfo.GetQuantizationOffset">GetQuantizationOffset</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetQuantizationScale" href="#pyarmnn.TensorInfo.GetQuantizationScale">GetQuantizationScale</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetShape" href="#pyarmnn.TensorInfo.GetShape">GetShape</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.IsQuantized" href="#pyarmnn.TensorInfo.IsQuantized">IsQuantized</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.IsTypeSpaceMatch" href="#pyarmnn.TensorInfo.IsTypeSpaceMatch">IsTypeSpaceMatch</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.SetDataType" href="#pyarmnn.TensorInfo.SetDataType">SetDataType</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.SetQuantizationOffset" href="#pyarmnn.TensorInfo.SetQuantizationOffset">SetQuantizationOffset</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.SetQuantizationScale" href="#pyarmnn.TensorInfo.SetQuantizationScale">SetQuantizationScale</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.SetShape" href="#pyarmnn.TensorInfo.SetShape">SetShape</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.thisown" href="#pyarmnn.TensorInfo.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape">TensorShape</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.TensorShape.GetNumDimensions" href="#pyarmnn.TensorShape.GetNumDimensions">GetNumDimensions</a></code></li>
<li><code><a title="pyarmnn.TensorShape.GetNumElements" href="#pyarmnn.TensorShape.GetNumElements">GetNumElements</a></code></li>
<li><code><a title="pyarmnn.TensorShape.thisown" href="#pyarmnn.TensorShape.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.TransposeConvolution2dDescriptor" href="#pyarmnn.TransposeConvolution2dDescriptor">TransposeConvolution2dDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_BiasEnabled" href="#pyarmnn.TransposeConvolution2dDescriptor.m_BiasEnabled">m_BiasEnabled</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_DataLayout" href="#pyarmnn.TransposeConvolution2dDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_PadBottom" href="#pyarmnn.TransposeConvolution2dDescriptor.m_PadBottom">m_PadBottom</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_PadLeft" href="#pyarmnn.TransposeConvolution2dDescriptor.m_PadLeft">m_PadLeft</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_PadRight" href="#pyarmnn.TransposeConvolution2dDescriptor.m_PadRight">m_PadRight</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_PadTop" href="#pyarmnn.TransposeConvolution2dDescriptor.m_PadTop">m_PadTop</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_StrideX" href="#pyarmnn.TransposeConvolution2dDescriptor.m_StrideX">m_StrideX</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_StrideY" href="#pyarmnn.TransposeConvolution2dDescriptor.m_StrideY">m_StrideY</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.thisown" href="#pyarmnn.TransposeConvolution2dDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>